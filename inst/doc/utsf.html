<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>utsf</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">utsf</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(utsf)</span></code></pre></div>
<p>In this document the <strong>utsf</strong> package is described. This
package offers a meta engine for applying different regression models
for univariate time series forecasting using an autoregressive
approach.</p>
<div id="univariate-time-series-forecasting-and-autoregressive-models" class="section level1">
<h1>Univariate time series forecasting and autoregressive models</h1>
<p>An univariate time series forecasting method is one in which the
future values of a series are predicted using only information from the
series, for example, using as forecast its mean historical value. An
advantage of this type of prediction is that, apart from the series
being forecast, there is no need to collect any further information in
order to train the forecasting model.</p>
<p>An autoregressive model is a kind of univariate time series
forecasting model in which a value of a time series is expressed as a
function of some of its past values. That is, an autoregressive model is
a regression model in which the independent variables are lagged values
(previous values) of the response variable. For example, given a time
series with the following historical values: <span class="math inline">\(t = \{1, 3, 6, 7, 9, 11, 16\}\)</span>, suppose
that we want to develop an autoregressive model in which a target “is
explained” by its first, second and fourth past values (in this context,
a previous value is also called a <em>lag</em>, so lag 1 is the value
immediately preceding a given value in the series). Given this series
and lags (1, 2 and 4), the training set would be:</p>
<table>
<thead>
<tr class="header">
<th>Lag 4</th>
<th>Lag 2</th>
<th>Lag 1</th>
<th>Target</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>6</td>
<td>7</td>
<td>9</td>
</tr>
<tr class="even">
<td>3</td>
<td>7</td>
<td>9</td>
<td>11</td>
</tr>
<tr class="odd">
<td>6</td>
<td>9</td>
<td>11</td>
<td>16</td>
</tr>
</tbody>
</table>
<p>In this model the next future value of the series is predicted as
<span class="math inline">\(f(Lag4, Lag2, Lag1)\)</span>, where <span class="math inline">\(f\)</span> is the regression function and <span class="math inline">\(Lag4\)</span>, <span class="math inline">\(Lag2\)</span> and <span class="math inline">\(Lag1\)</span> are the fourth, second and first
lagged values of the next future value. So, the next future value of
series <span class="math inline">\(t\)</span> is predicted as <span class="math inline">\(f(7, 11, 16)\)</span>, producing a value that will
be called <span class="math inline">\(F1\)</span>.</p>
<p>Suppose that the forecast horizon (the number of future values to be
forecast into the future) is greater than 1. In the case that the
regression function only predicts the next future value of the series, a
recursive approach can be applied to forecast all the future values of
the forecast horizon. Using a recursive approach, the regression
function is applied recursively until all horizons are forecast. For
instance, following the previous example, suppose that the forecast
horizon is 3. As we have explained, to forecast the next future value of
the series (horizon 1) the regression function is fed with the vector
<span class="math inline">\([7, 11, 16]\)</span>, producing <span class="math inline">\(F1\)</span>. To forecast horizon 2 the regression
function is fed with the vector <span class="math inline">\([9, 16,
F1]\)</span>. The forecast for horizon 1, <span class="math inline">\(F1\)</span>, is used as the first lag for horizon
2 because the actual value is unknown. Finally, to predict horizon 3 the
regression function is fed with the vector [<span class="math inline">\(11, F1, F2]\)</span>. This example of recursive
forecast is summarized in the following table:</p>
<table>
<thead>
<tr class="header">
<th>Horizon</th>
<th>Autoregressive values</th>
<th>Forecast</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>7, 11, 16</td>
<td>F1</td>
</tr>
<tr class="even">
<td>2</td>
<td>9, 16, F1</td>
<td>F2</td>
</tr>
<tr class="odd">
<td>3</td>
<td>11, F1, F2</td>
<td>F3</td>
</tr>
</tbody>
</table>
<p>The recursive approach for forecasting several values into the future
is applied in classical statistical models such as ARIMA or exponential
smoothing.</p>
</div>
<div id="the-utsf-package" class="section level1">
<h1>The utsf package</h1>
<p>The <strong>utsf</strong> package makes it easy the use of classical
regression models for univariate time series forecasting employing the
autoregressive approach and the recursive prediction strategy explained
in the previous section. All the supported models are applied using an
uniform interface: the <code>create_model()</code> function to build the
forecasting model and the <code>forecast()</code> function for using the
model to predict the future values. Let us see an example in which a
regression tree model is used to forecast the next future values of a
time series:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> <span class="st">&quot;rt&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">12</span>)</span></code></pre></div>
<p>In this example, an autoregressive tree model
(<code>method = &quot;rt&quot;</code>) is trained using the historical values of
the <code>AirPassengers</code> time series and a forecast for its 12
next future values (<code>h = 12</code>) is done. The
<code>create_model()</code> function returns an S3 object of class
<code>utsf</code> with information about the trained model. The
information about the forecast is included in the object returned by the
<code>forecast()</code> function as a component named <code>pred</code>
of class <code>ts</code> (a time series):</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>f<span class="sc">$</span>pred</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co">#&gt;           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co">#&gt; 1961 460.2980 428.4915 467.0304 496.9833 499.9819 554.7891 627.5849 628.0503</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co">#&gt;           Sep      Oct      Nov      Dec</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co">#&gt; 1961 533.2803 482.4221 448.7926 453.6920</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>The training set used to fit the model is built from the historical
values of the time series using the autoregressive approach explained in
the previous section. The <code>lags</code> parameter of the
<code>create_model()</code> function is used to specify the
autoregressive lags. In the example: <code>lags = 1:12</code>, so a
target is a function of its 12 previous values. Next, we consult the
first targets (and their associated features) with which the regression
model has been trained:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">head</span>(m<span class="sc">$</span>targets)  <span class="co"># first targets</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co">#&gt; [1] -11.6666667  -0.9166667  13.4166667   6.6666667  -3.8333333  19.8333333</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="fu">head</span>(m<span class="sc">$</span>features) <span class="co"># and its associated features</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co">#&gt;         Lag12     Lag11     Lag10      Lag9       Lag8       Lag7       Lag6</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">#&gt; 1 -14.6666667 -8.666667  5.333333  2.333333  -5.666667   8.333333  21.333333</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#&gt; 2  -8.9166667  5.083333  2.083333 -5.916667   8.083333  21.083333  21.083333</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co">#&gt; 3   4.4166667  1.416667 -6.583333  7.416667  20.416667  20.416667   8.416667</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co">#&gt; 4   0.6666667 -7.333333  6.666667 19.666667  19.666667   7.666667  -9.333333</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co">#&gt; 5  -7.8333333  6.166667 19.166667 19.166667   7.166667  -9.833333 -24.833333</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co">#&gt; 6   5.8333333 18.833333 18.833333  6.833333 -10.166667 -25.166667 -11.166667</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="co">#&gt;         Lag5       Lag4       Lag3       Lag2       Lag1</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a><span class="co">#&gt; 1  21.333333   9.333333  -7.666667 -22.666667  -8.666667</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a><span class="co">#&gt; 2   9.083333  -7.916667 -22.916667  -8.916667 -11.916667</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="co">#&gt; 3  -8.583333 -23.583333  -9.583333 -12.583333  -1.583333</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a><span class="co">#&gt; 4 -24.333333 -10.333333 -13.333333  -2.333333  12.666667</span></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a><span class="co">#&gt; 5 -10.833333 -13.833333  -2.833333  12.166667   6.166667</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a><span class="co">#&gt; 6 -14.166667  -3.166667  11.833333   5.833333  -4.166667</span></span></code></pre></div>
<p>Using the example of the previous section:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>, <span class="dv">16</span>))</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">create_model</span>(t, <span class="at">lags =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>), <span class="at">preProcess =</span> <span class="fu">list</span>(<span class="fu">trend</span>(<span class="st">&quot;none&quot;</span>)))</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="fu">cbind</span>(out<span class="sc">$</span>features, <span class="at">Target =</span> out<span class="sc">$</span>targets)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co">#&gt;   Lag4 Lag2 Lag1 Target</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">#&gt; 1    1    6    7      9</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">#&gt; 2    3    7    9     11</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">#&gt; 3    6    9   11     16</span></span></code></pre></div>
</div>
<div id="prediction-intervals" class="section level1">
<h1>Prediction intervals</h1>
<p>Prediction intervals for the forecast can be computed:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(USAccDeaths, <span class="at">method =</span> <span class="st">&quot;mt&quot;</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">12</span>, <span class="at">PI =</span> <span class="cn">TRUE</span>, <span class="at">level =</span> <span class="dv">90</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>f</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co">#&gt;          Point Forecast    Lo 90     Hi 90</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#&gt; Jan 1979       8162.724 7637.168  8734.505</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">#&gt; Feb 1979       7185.788 6599.334  7756.071</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">#&gt; Mar 1979       7475.744 6906.230  8074.220</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt; Apr 1979       7836.936 7286.239  8393.013</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co">#&gt; May 1979       8570.632 8009.798  9195.543</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co">#&gt; Jun 1979       9018.691 8506.675  9607.082</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="co">#&gt; Jul 1979       9865.224 9301.012 10450.300</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="co">#&gt; Aug 1979       9695.409 9121.060 10282.676</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a><span class="co">#&gt; Sep 1979       9160.569 8573.021  9741.959</span></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="co">#&gt; Oct 1979       8962.662 8390.299  9564.492</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="co">#&gt; Nov 1979       8606.452 8016.662  9185.467</span></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a><span class="co">#&gt; Dec 1979       8899.133 8330.878  9496.445</span></span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>Prediction intervals are calculated following the guidelines in (<a href="https://otexts.com/fpp3/nnetar.html#prediction-intervals-5" class="uri">https://otexts.com/fpp3/nnetar.html#prediction-intervals-5</a>).
Random errors are assumed to follow a normal distribution.</p>
</div>
<div id="supported-models" class="section level1">
<h1>Supported models</h1>
<p>The <code>create_model()</code> and <code>forecast()</code> functions
provide a common interface to applying an autoregressive approach for
time series forecasting using different regression models. These models
are implemented in several R packages. Currently, our project is mainly
focused on regression tree models, supporting the following
approaches:</p>
<ul>
<li>k-nearest neighbors: In this case no model is trained and the
function <code>FNN::knn.reg()</code> is used, as regression function, to
recursively predict the future values of the time series.</li>
<li>Linear models: The model is trained using the function
<code>stats::lm()</code> and its associated method
<code>stats::predict.lm()</code> is applied recursively for the
forecasts, i.e., as regression function.</li>
<li>Regression trees: The model is trained using the function
<code>rpart::rpart()</code> and its associated method
<code>rpart::predict.rpart()</code> is used for the forecasts.</li>
<li>Model trees: The model is trained with the function
<code>Cubist::cubist()</code> and its associated method
<code>Cubist::predict.cubist()</code> is used for predictions.</li>
<li>Bagging: The model is trained with the function
<code>ipred::bagging()</code> and its associated method
<code>ipred::predict.regbagg()</code> is used for forecasting.</li>
<li>Random forest: The model is trained with the function
<code>ranger::ranger()</code> and its associated method
<code>ranger::predict.ranger()</code> is used for predictions.</li>
</ul>
<p>The S3 object of class <code>utsf</code> returned by the
<code>create_model()</code> function contains a component with the
trained autoregressive model:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(fdeaths, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> <span class="st">&quot;rt&quot;</span>)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>m<span class="sc">$</span>model</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co">#&gt; n= 60 </span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co">#&gt; node), split, n, deviance, yval</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="co">#&gt;       * denotes terminal node</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="co">#&gt; 1) root 60 1967124.00   -6.465278  </span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="co">#&gt;   2) Lag12&lt; 73 38  212851.90 -124.414500  </span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co">#&gt;     4) Lag6&gt;=-66.45833 30   57355.07 -153.847200  </span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="co">#&gt;       8) Lag12&lt; -170.7083 10   13293.09 -195.991700 *</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co">#&gt;       9) Lag12&gt;=-170.7083 20   17419.67 -132.775000 *</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="co">#&gt;     5) Lag6&lt; -66.45833 8   32051.01  -14.041670 *</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="co">#&gt;   3) Lag12&gt;=73 22  312482.00  197.265200  </span></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="co">#&gt;     6) Lag5&gt;=-131.7917 7   24738.12  114.500000 *</span></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a><span class="co">#&gt;     7) Lag5&lt; -131.7917 15  217416.40  235.888900 *</span></span></code></pre></div>
<p>In this case, the model is the result of training a regression tree
using the function <code>rpart::rpart()</code> with the training set
consisting of the features <code>m$features</code> and targets
<code>m$targets</code>. Once the model is trained, the
<code>rpart::predict.rpart()</code> function can be used recursively to
forecast the future values of the time series using the
<code>forecast()</code> function.</p>
</div>
<div id="using-your-own-models" class="section level1">
<h1>Using your own models</h1>
<p>An interesting feature of the <strong>utsf</strong> package is that
you can use it to apply your own regression models for time series
forecasting in an autoregressive way. Thus, your regression models can
benefit from the features implemented in the package, such as
pre-processing, parameter tuning, the building of the training set, the
implementation of recursive forecasts or the estimation of the forecast
accuracy of a model.</p>
<p>To apply your own regression model you have to use the
<code>method</code> parameter of the <code>create_model()</code>
function, providing as argument a function that is able to train your
model. This function should return an object with the trained regression
model. Also, it must have at least two input parameters:</p>
<ul>
<li><code>X</code>: it is a data frame with the features of the training
examples. This data frame is built from the time series taking into
account the autoregressive lags as explained in a previous section. This
is the same object as the <code>features</code> component of the object
returned by the <code>create_model()</code> function.</li>
<li><code>y</code>: a vector with the targets of the training examples.
It is built as explained in a previous section. It is the same object as
the <code>targets</code> component of the object returned by the
<code>create_model()</code> function.</li>
</ul>
<p>Furthermore, if the function that trains the model (the function
provided for the <code>method</code> parameter) returns a model of class
<code>model_class</code>, a method with the signature
<code>predict.model_class(object, new_value)</code> should be
implemented. This method uses your model to predict a new value, that
is, it is the regression function associated with the model.</p>
<p>Let us see an example in which a time series is forecast using the
k-nearest neighbors regression model implemented in the package FNN:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Function to train the regression model</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>my_knn_model <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, <span class="at">k =</span> <span class="dv">3</span>) {</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>  <span class="fu">structure</span>(<span class="fu">list</span>(<span class="at">X =</span> X, <span class="at">y =</span> y, <span class="at">k =</span> k), <span class="at">class =</span> <span class="st">&quot;my_knn&quot;</span>)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>}</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co"># Function to predict a new example</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>predict.my_knn <span class="ot">&lt;-</span> <span class="cf">function</span>(object, new_value) {</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>  FNN<span class="sc">::</span><span class="fu">knn.reg</span>(<span class="at">train =</span> object<span class="sc">$</span>X, <span class="at">test =</span> new_value,</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>               <span class="at">y =</span> object<span class="sc">$</span>y, <span class="at">k =</span> object<span class="sc">$</span>k)<span class="sc">$</span>pred</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>}</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> my_knn_model)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">12</span>)</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>f<span class="sc">$</span>pred</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="co">#&gt;           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="co">#&gt; 1961 455.9167 434.3264 480.7703 490.1678 506.1262 568.0534 640.6689 640.8636</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="co">#&gt;           Sep      Oct      Nov      Dec</span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a><span class="co">#&gt; 1961 549.5467 495.4255 441.6554 476.7934</span></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>The <code>new_value</code> parameter of the <code>predict</code>
method receives a data frame with the same structure as the
<code>X</code> parameter of the function for building the model. The
<code>new_value</code> data frame has only one row, with the features of
the example to be predicted.</p>
<p>The k-nearest neighbors algorithm is so simple that it can be easily
implemented without using functionality from any R package:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Function to train the regression model</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>my_knn_model2 <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, <span class="at">k =</span> <span class="dv">3</span>) {</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>  <span class="fu">structure</span>(<span class="fu">list</span>(<span class="at">X =</span> X, <span class="at">y =</span> y, <span class="at">k =</span> k), <span class="at">class =</span> <span class="st">&quot;my_knn2&quot;</span>)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>}</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co"># Function to predict a new example</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>predict.my_knn2 <span class="ot">&lt;-</span> <span class="cf">function</span>(object, new_value) {</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>  distances <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(object<span class="sc">$</span>X), <span class="cf">function</span>(i) <span class="fu">sum</span>((object<span class="sc">$</span>X[i, ] <span class="sc">-</span> new_value)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>  k_nearest <span class="ot">&lt;-</span> <span class="fu">order</span>(distances)[<span class="dv">1</span><span class="sc">:</span>object<span class="sc">$</span>k]</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>  <span class="fu">mean</span>(object<span class="sc">$</span>y[k_nearest])</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>}</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> my_knn_model2)</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a><span class="fu">forecast</span>(m2, <span class="at">h =</span> <span class="dv">12</span>)<span class="sc">$</span>pred</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a><span class="co">#&gt;           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug</span></span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a><span class="co">#&gt; 1961 455.9167 434.3264 480.7703 490.1678 506.1262 568.0534 640.6689 640.8636</span></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a><span class="co">#&gt;           Sep      Oct      Nov      Dec</span></span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a><span class="co">#&gt; 1961 549.5467 495.4255 441.6554 476.7934</span></span></code></pre></div>
</div>
<div id="setting-the-parameters-of-the-regression-models" class="section level1">
<h1>Setting the parameters of the regression models</h1>
<p>Normally, a regression model can be adjusted using different
parameters. By default, the models supported by our package are set
using some specific parameters, usually the default values of the
functions used to train the models (these functions are listed in a
previous section). However, the user can set the parameters used to
train the regression models with the <code>param</code> argument of the
<code>create_model()</code> function. The <code>param</code> argument
must be a list with the names and values of the parameters to be set.
Let us see an example:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># A bagging model set with default parameters</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> <span class="st">&quot;bagging&quot;</span>)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="fu">length</span>(m<span class="sc">$</span>model<span class="sc">$</span>mtrees) <span class="co"># number of regression trees (25 by default)</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co">#&gt; [1] 25</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co"># A bagging model set with 3 regression tress</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers,</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>              <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>,</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>              <span class="at">method =</span> <span class="st">&quot;bagging&quot;</span>,</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>              <span class="at">param =</span> <span class="fu">list</span>(<span class="at">nbagg =</span> <span class="dv">3</span>)</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>)</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="fu">length</span>(m2<span class="sc">$</span>model<span class="sc">$</span>mtrees) <span class="co"># number of regression trees</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="co">#&gt; [1] 3</span></span></code></pre></div>
<p>In the previous example, two bagging models (using regression trees)
are trained with the <code>create_model()</code> function. In the first
model the number of trees is 25, the default value of the function
<code>ipred::ipredbagg()</code> used to train the model. In the second
model the number of trees is set to 3. Of course, in order to set some
specific parameters the user must consult the arguments of the function
used internally by the <code>create_model()</code> function to train the
model. In the example, <code>ipred::ipredbagg()</code>.</p>
<p>In the following example the user sets the parameters of a regression
model implemented by himself/herself:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># Function to train the model</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>my_knn_model <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, <span class="at">k =</span> <span class="dv">3</span>) {</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>  <span class="fu">structure</span>(<span class="fu">list</span>(<span class="at">X =</span> X, <span class="at">y =</span> y, <span class="at">k =</span> k), <span class="at">class =</span> <span class="st">&quot;my_knn&quot;</span>)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>}</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co"># Regression function for object of class my_knn</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>predict.my_knn <span class="ot">&lt;-</span> <span class="cf">function</span>(object, new_value) {</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>  FNN<span class="sc">::</span><span class="fu">knn.reg</span>(<span class="at">train =</span> object<span class="sc">$</span>X, <span class="at">test =</span> new_value,</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>               <span class="at">y =</span> object<span class="sc">$</span>y, <span class="at">k =</span> object<span class="sc">$</span>k)<span class="sc">$</span>pred</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>}</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a><span class="co"># The model is trained with default parameters (k = 3)</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>,  <span class="at">method =</span> my_knn_model)</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a><span class="fu">print</span>(m<span class="sc">$</span>model<span class="sc">$</span>k)</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a><span class="co">#&gt; [1] 3</span></span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a><span class="co"># The model is trained with k = 5</span></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">method =</span> my_knn_model, <span class="at">param =</span> <span class="fu">list</span>(<span class="at">k =</span> <span class="dv">5</span>))</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a><span class="fu">print</span>(m2<span class="sc">$</span>model<span class="sc">$</span>k)</span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a><span class="co">#&gt; [1] 5</span></span></code></pre></div>
</div>
<div id="estimating-forecast-accuracy" class="section level1">
<h1>Estimating forecast accuracy</h1>
<p>This section explains how to estimate the forecast accuracy of a
regression model predicting a time series with the <strong>utsf</strong>
package. Let us see an example:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(UKgas, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">type =</span> <span class="st">&quot;normal&quot;</span>, <span class="at">size =</span> <span class="dv">8</span>)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>r<span class="sc">$</span>per_horizon</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="co">#&gt;       Horizon 1 Horizon 2 Horizon 3 Horizon 4</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="co">#&gt; MAE   40.956667 37.205000 42.730417 51.424167</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="co">#&gt; MAPE   4.118140  5.030128  7.468098  7.434864</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="co">#&gt; sMAPE  4.261377  5.208551  7.814417  7.732037</span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="co">#&gt; RMSE  58.920772 47.660996 49.733955 55.023038</span></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>r<span class="sc">$</span>global</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a><span class="co">#&gt;       MAE      MAPE     sMAPE      RMSE </span></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a><span class="co">#&gt; 43.079063  6.012808  6.254095 52.834690</span></span></code></pre></div>
<p>To assess the forecast accuracy of a forecasting model you should use
the <code>efa()</code> function on the model. In this case, the
forecasting method is a k-nearest neighbors algorithm
(<code>method = &quot;knn&quot;</code>) with the autoregressive lags 1 to 4
applied on the <code>UKgas</code> time series. An estimation of its
forecast accuracy on the series for a forecasting horizon of 4
(<code>h = 4</code>) is obtained according to different forecast
accuracy measures. The <code>efa()</code> function returns a list with
two components. The component named <code>per_horizon</code> contains
the forecast accuracy estimations per forecasting horizon. The component
named <code>global</code> is computed as the means of the rows of the
<code>per_horizon</code> component. Currently, the following forecast
accuracy measures are computed:</p>
<ul>
<li>MAE: mean absolute error</li>
<li>MAPE: mean absolute percentage error</li>
<li>sMAPE: symmetric MAPE</li>
<li>RMSE: root mean squared error</li>
</ul>
<p>Next, we describe how the forecasting accuracy measures are computed
for a forecasting horizon <span class="math inline">\(h\)</span> (<span class="math inline">\(y_t\)</span> and <span class="math inline">\(\hat{y}_t\)</span> are the actual future value and
its forecast for horizon <span class="math inline">\(t\)</span>
respectively):</p>
<p><span class="math display">\[
MAE = \frac{1}{h}\sum_{t=1}^{h} |y_t-\hat{y}_t|
\]</span></p>
<p><span class="math display">\[
MAPE = \frac{1}{h}\sum_{t=1}^{h} 100\frac{|y_t-\hat{y}_t|}{y_t}
\]</span> <span class="math display">\[
sMAPE = \frac{1}{h}\sum_{t=1}^{h}
200\frac{\left|y_{t}-\hat{y}_{t}\right|}{|y_t|+|\hat{y}_t|}
\]</span></p>
<p><span class="math display">\[
RMSE = \sqrt{\frac{1}{h}\sum_{t=1}^{h} (y_t-\hat{y}_t)^2}
\]</span></p>
<p>The estimation of forecast accuracy is done with the well-known
rolling origin evaluation. This technique builds several training and
test sets from the series, as shown below for a forecasting horizon of
4:</p>
<p><img role="img" src="data:image/png;base64,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" width="85%" /></p>
<p>In this case the last nine observations of the series are usedto
build the test sets. Six models are trained using the different training
sets and their forecasts are compared to their corresponding test sets.
Thus, the estimation of the forecast error for every forecasting horizon
is based on six errors (it is computed as the mean).</p>
<p>You can specify how many of the last observations of the series are
used to build the test sets with the <code>size</code> and
<code>prop</code> parameters. For example:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(UKgas, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="co"># Use the last 9 observations of the series to build test sets</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>r1 <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">type =</span> <span class="st">&quot;normal&quot;</span>, <span class="at">size =</span> <span class="dv">9</span>)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a><span class="co"># Use the last 20% observations of the series to build test sets</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>r2 <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">type =</span> <span class="st">&quot;normal&quot;</span>, <span class="at">prop =</span> <span class="fl">0.2</span>)</span></code></pre></div>
<p>If the series is short, the training sets might be too small to fit a
meaningful model. In that case, a special rolling origin evaluation can
be done with the <code>type</code> parameter set to
<code>minimum</code>:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(UKgas, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">type =</span> <span class="st">&quot;minimum&quot;</span>)</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>r<span class="sc">$</span>per_horizon</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co">#&gt;       Horizon 1 Horizon 2 Horizon 3 Horizon 4</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="co">#&gt; MAE   47.893750 44.934722 44.918229 26.961198</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="co">#&gt; MAPE   5.745458  6.757300  8.250563  3.444200</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a><span class="co">#&gt; sMAPE  5.761843  6.791762  8.329877  3.385892</span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co">#&gt; RMSE  56.558584 52.858868 46.912818 26.961198</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>r<span class="sc">$</span>global</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a><span class="co">#&gt;       MAE      MAPE     sMAPE      RMSE </span></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="co">#&gt; 41.176975  6.049380  6.067343 45.822867</span></span></code></pre></div>
<p>When this option is chosen the last <code>h</code> observations (in
the example 4) are used to build the training sets as is shown below for
<code>h = 4</code>:</p>
<p><img role="img" src="data:image/png;base64,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" width="85%" /></p>
<p>In this case the estimated forcast error for horizon 1 is based on 4
errors, for horizon 2 is based on 3 errors, for horizon 3 on 2 errors
and for horizon 4 on 1 error.</p>
<p>The efa() function also returns the test sets (and the predictions
associated with them) used when assessing the forecast accuracy:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>timeS <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(timeS, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">method =</span> <span class="st">&quot;mt&quot;</span>)</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">5</span>, <span class="at">size =</span> <span class="dv">7</span>)</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>r<span class="sc">$</span>test_sets</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a><span class="co">#&gt;      h=1 h=2 h=3 h=4 h=5</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="co">#&gt; [1,]  19  20  21  22  23</span></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="co">#&gt; [2,]  20  21  22  23  24</span></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="co">#&gt; [3,]  21  22  23  24  25</span></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>r<span class="sc">$</span>predictions</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a><span class="co">#&gt;      h=1 h=2 h=3 h=4 h=5</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="co">#&gt; [1,]  19  20  21  22  23</span></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="co">#&gt; [2,]  20  21  22  23  24</span></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a><span class="co">#&gt; [3,]  21  22  23  24  25</span></span></code></pre></div>
<p>Each row in these tables represent a test set or prediction. Let us
see the test sets when the “minimum” evaluation is done:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>timeS <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>)</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(timeS, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">method =</span> <span class="st">&quot;mt&quot;</span>)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">3</span>, <span class="at">type =</span> <span class="st">&quot;minimum&quot;</span>)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>r<span class="sc">$</span>test_sets</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="co">#&gt;      [,1] [,2] [,3]</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a><span class="co">#&gt; [1,]   25   NA   NA</span></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a><span class="co">#&gt; [2,]   24   25   NA</span></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="co">#&gt; [3,]   23   24   25</span></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>r<span class="sc">$</span>predictions</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="co">#&gt;      [,1] [,2] [,3]</span></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a><span class="co">#&gt; [1,]   25   NA   NA</span></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a><span class="co">#&gt; [2,]   24   25   NA</span></span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="co">#&gt; [3,]   23   24   25</span></span></code></pre></div>
</div>
<div id="parameter-tuning" class="section level1">
<h1>Parameter tuning</h1>
<p>Another useful feature of the <strong>utsf</strong> package is
parameter tuning. The <code>tune_grid()</code> function allows you to
estimate the forecast accuracy of a model using different combinations
of parameters. Furthermore, the best combination of parameters is used
to train a model with all the historical values of the series and the
model is applied for forecasting the future values of the series. Let us
see an example:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(UKgas, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">k =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>), <span class="at">type =</span> <span class="st">&quot;normal&quot;</span>, <span class="at">size =</span> <span class="dv">8</span>)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a><span class="co"># To see the estimated forecast accuracy with the different configurations</span></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>r<span class="sc">$</span>tuneGrid</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a><span class="co">#&gt;   k      MAE     MAPE    sMAPE     RMSE</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="co">#&gt; 1 1 27.50551 4.195273 4.344649 38.72080</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a><span class="co">#&gt; 2 2 41.67751 5.782108 5.995799 50.67769</span></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a><span class="co">#&gt; 3 3 43.07906 6.012808 6.254095 52.83469</span></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a><span class="co">#&gt; 4 4 43.58916 6.206692 6.382526 55.14836</span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a><span class="co">#&gt; 5 5 46.03185 6.332209 6.503322 58.41501</span></span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a><span class="co">#&gt; 6 6 47.64410 6.441446 6.583134 62.46201</span></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a><span class="co">#&gt; 7 7 48.95917 6.841679 6.886563 63.75997</span></span></code></pre></div>
<p>In this example, the <code>tuneGrid</code> parameter is used to
specify (using a data frame) the set of parameters to assess. The
forecast accuracy of the model for the different combinations of
parameters is estimated as explained in the previous section using the
last observations of the time series as validation set. The
<code>size</code> parameter is used to specify the size of the test set.
The <code>tuneGrid</code> component of the list returned by the
<code>tune_grid()</code> function contains the result of the estimation.
In this case, the k-nearest neighbors method using <span class="math inline">\(k=1\)</span> obtains the best results for all the
forecast accuracy measures. The best combination of parameters according
to RMSE is used to forecast the time series:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>r<span class="sc">$</span>best</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="co">#&gt; $k</span></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="co">#&gt; [1] 1</span></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>r<span class="sc">$</span>forecast</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a><span class="co">#&gt;           Qtr1      Qtr2      Qtr3      Qtr4</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a><span class="co">#&gt; 1987 1217.9250  661.4063  388.1828  817.3785</span></span></code></pre></div>
<p>Let us plot the values of <span class="math inline">\(k\)</span>
against their estimated accuracy using RMSE:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="fu">plot</span>(r<span class="sc">$</span>tuneGrid<span class="sc">$</span>k, r<span class="sc">$</span>tuneGrid<span class="sc">$</span>RMSE, <span class="at">type =</span> <span class="st">&quot;o&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">xlab =</span> <span class="st">&quot;k (number of nearest neighbors)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;RMSE&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Estimated accuracy&quot;</span>)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
</div>
<div id="preprocessings-and-transformations" class="section level1">
<h1>Preprocessings and transformations</h1>
<p>Sometimes, the forecast accuracy of a model can be improved by
applying some transformations and/or preprocessings to the time series
being forecast. Currently, the <strong>utsf</strong> package is focused
on preprocessings related to forecasting time series with a trend. This
is due to the fact that, at present, the models incorporated in our
package (such as regression trees and k-nearest neighbors) predict
averages of the targets in the training set (i.e., an average of
historical values of the series). In a trended series these averages are
probably outside the range of the future values of the series. Let us
see an example in which a trended series (the yearly revenue passenger
miles flown by commercial airlines in the United States) is forecast
using a random forest model:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(airmiles, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">preProcess =</span> <span class="fu">list</span>(<span class="fu">trend</span>(<span class="st">&quot;none&quot;</span>)))</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>In this case, no preprocessing is applied
(<code>preProcess = list(trend(&quot;none&quot;))</code>). It can be observed how
the forecast does not capture the trending behavior of the series
because regression tree models predict averaged values of the training
targets.</p>
<p>In the next subsections we explain how to deal with trended series
using three different transformations.</p>
<div id="differencing" class="section level2">
<h2>Differencing</h2>
<p>A common way of dealing with trended series is to transform the
original series taking first differences (computing the differences
between consecutive observations). Then, the model is trained with the
differenced series and the forecasts are back-transformed. Let us see an
example:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(airmiles, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">preProcess =</span> <span class="fu">list</span>(<span class="fu">trend</span>(<span class="st">&quot;differences&quot;</span>, <span class="dv">1</span>)))</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>In this case, the <code>preProcess</code> parameter has been used to
specify first-order differences. The <code>preProcess</code> parameter
consists of a list of preprocessings or transformations. Currently, only
one preprocessing can be specified. The order of first differences is
specified with the second parameter of the <code>trend()</code> function
(normally 1). It is also possible to specify the value -1, in which case
the order of differences is estimated using the <code>ndiffs()</code>
function from the <strong>forecast</strong> package (in that case the
chosen order of first differences could be 0, that is, no differences
are applied).</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="co"># The order of first differences is estimated using the ndiffs function</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(airmiles, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">preProcess =</span> <span class="fu">list</span>(<span class="fu">trend</span>(<span class="st">&quot;differences&quot;</span>, <span class="dv">1</span>)))</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>m<span class="sc">$</span>differences</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a><span class="co">#&gt; Order of first differences: 1</span></span></code></pre></div>
</div>
<div id="the-additive-transformation" class="section level2">
<h2>The additive transformation</h2>
<p>This transformation has been used to deal with trending series in
other packages, such as <strong>tsknn</strong> and
<strong>tsfgrnn</strong>. The additive transformation works transforming
the training examples as follows:</p>
<ul>
<li>A vector of features is transformed by subtracting the mean of the
vector.</li>
<li>The target associated with a vector of features is transformed by
subtracting from it the mean of its associated vector of features.</li>
<li>To back transform a prediction, the mean of the input vector is
added to it.</li>
</ul>
<p>It is easy to check how the training examples are modified by the
additive transformation using the API of the package. For example, let
us see the training examples of a model with no transformation:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>timeS <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">12</span>))</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(timeS, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">preProcess =</span> <span class="fu">list</span>(<span class="fu">trend</span>(<span class="st">&quot;none&quot;</span>)))</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="fu">cbind</span>(m<span class="sc">$</span>features, <span class="at">Targets =</span> m<span class="sc">$</span>targets)</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a><span class="co">#&gt;   Lag2 Lag1 Targets</span></span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a><span class="co">#&gt; 1    1    3       7</span></span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a><span class="co">#&gt; 2    3    7       9</span></span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a><span class="co">#&gt; 3    7    9      10</span></span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a><span class="co">#&gt; 4    9   10      12</span></span></code></pre></div>
<p>Now, let us see the effect of the additive transformation in the
training examples:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>timeS <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">12</span>))</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(timeS, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">preProcess =</span> <span class="fu">list</span>(<span class="fu">trend</span>(<span class="st">&quot;additive&quot;</span>)))</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a><span class="fu">cbind</span>(m<span class="sc">$</span>features, <span class="at">Targets =</span> m<span class="sc">$</span>targets)</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a><span class="co">#&gt;   Lag2 Lag1 Targets</span></span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a><span class="co">#&gt; 1 -1.0  1.0     5.0</span></span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a><span class="co">#&gt; 2 -2.0  2.0     4.0</span></span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a><span class="co">#&gt; 3 -1.0  1.0     2.0</span></span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a><span class="co">#&gt; 4 -0.5  0.5     2.5</span></span></code></pre></div>
<p>Finally, we forecast the airmiles series using the additive
transformation and a random forest model:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(airmiles, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>)</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>In this last code snippet we have used the default value of
<code>preProcess</code>, because it applies the additive
transformation.</p>
</div>
<div id="the-multiplicative-transformation" class="section level2">
<h2>The multiplicative transformation</h2>
<p>The multiplicative transformation is similar to the additive
transformation, but it is intended for series with an exponential trend
(the additive transformation is suited for series with a linear trend).
In the multiplicative transformation a training example is transformed
this way:</p>
<ul>
<li>A vector of features is transformed by dividing it by its mean.</li>
<li>The target associated with a vector of features is transformed by
dividing it by the mean of its associated vector of features.</li>
<li>To back transform a prediction, the prediction is multiplied by the
mean of the input vector.</li>
</ul>
<p>Let us see an example of an artificial time series with a
multiplicative trend and its forecast using the additive and the
multiplicative transformation:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="dv">10</span> <span class="sc">*</span> <span class="fl">1.05</span><span class="sc">^</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>))</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>m_m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(t, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">preProcess =</span> <span class="fu">list</span>(<span class="fu">trend</span>(<span class="st">&quot;multiplicative&quot;</span>)))</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>f_m <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m_m, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a>m_a <span class="ot">&lt;-</span> <span class="fu">create_model</span>(t, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">preProcess =</span> <span class="fu">list</span>(<span class="fu">trend</span>(<span class="st">&quot;additive&quot;</span>)))</span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a>f_a <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m_a, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a><span class="fu">library</span>(vctsfr)</span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a><span class="fu">plot_predictions</span>(t, <span class="at">predictions =</span> <span class="fu">list</span>(<span class="at">Multiplicative =</span> f_m<span class="sc">$</span>pred, <span class="at">Additive =</span> f_a<span class="sc">$</span>pred))</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>In this case, the forecast with the multiplicative transformation
captures perfectly the exponential trend.</p>
</div>
</div>
<div id="default-parameters" class="section level1">
<h1>Default parameters</h1>
<p>The <code>create_model()</code> function only has one compulsory
parameters: the time series with which the model is trained. Next, we
discuss the default values for the rest of its parameters:</p>
<ul>
<li><code>lags</code>: The <code>lags</code> parameter is an integer
vector (in increasing order) with the autoregressive lags. If
<code>frequency(ts) == f</code> where <code>ts</code> is the time series
being forecast and <span class="math inline">\(f &gt; 1\)</span> then
the lags used as autoregressive features are 1:<em>f</em>. For example,
the lags for quarterly data are 1:4 and for monthly data 1:12. This is
useful to capture a possible seasonal behavior of the series. If
<code>frequency(ts) == 1</code>, then:
<ul>
<li>The lags with significant autocorrelation in the partial
autocorrelation function (<code>stats::pacf()</code>) are selected.</li>
<li>If no lag has a significant autocorrelation, then lags 1:5 are
chosen.</li>
<li>If only one lag has significant autocorrelation and the additive or
multiplicative transformation is applied, then lags 1:5 are chosen. This
is done because it does not make sense to use these transformations with
only one autoregressive lag.</li>
</ul></li>
<li><code>method</code>: By default, the k-nearest neighbors algorithm
is applied.</li>
<li><code>param</code>: By default, the model is trained using some
sensible parameters, normally the default values of the function used to
train the model.</li>
<li><code>preProcess</code>: The additive transformation is applied.
This transformation have proved its effectiveness to forecast trending
series. In general, its application seems beneficial on any kind of
series.</li>
</ul>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
