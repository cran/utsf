<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>utsf</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">utsf</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(utsf)</span></code></pre></div>
<p>In this document the <strong>utsf</strong> package is described. This
package offers a meta engine for applying different regression models
for univariate time series forecasting using an autoregressive approach.
One main feature of the package is its extensibility, which allow you to
use machine learning models not directly supported by the package, such
as neural networks, or your own models.</p>
<div id="univariate-time-series-forecasting-autoregressive-models-and-recursive-forecasts" class="section level1">
<h1>Univariate time series forecasting ( autoregressive models) and
recursive forecasts</h1>
<p>An univariate time series forecasting method is one in which the
future values of a series are predicted using only information from the
series, for example, using as forecast its mean historical value. An
advantage of this type of prediction is that, apart from the series
being forecast, there is no need to collect any further information in
order to train the forecasting model.</p>
<p>An autoregressive model is a kind of univariate time series
forecasting model in which a value of a time series is expressed as a
function of some of its past values. That is, an autoregressive model is
a regression model in which the independent variables are lagged values
(previous values) of the response variable. For example, given a time
series with the following historical values: <span class="math inline">\(t = \{1, 3, 6, 7, 9, 11, 16\}\)</span>, suppose
that we want to develop an autoregressive model in which a target “is
explained” by its first, second and fourth past values (in this context,
a previous value is also called a <em>lag</em>, so lag 1 is the value
immediately preceding a given value in the series). Given the series
<span class="math inline">\(t\)</span> and lags (1, 2 and 4), the
training set would be:</p>
<table>
<thead>
<tr class="header">
<th>Lag 4</th>
<th>Lag 2</th>
<th>Lag 1</th>
<th>Target</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>6</td>
<td>7</td>
<td>9</td>
</tr>
<tr class="even">
<td>3</td>
<td>7</td>
<td>9</td>
<td>11</td>
</tr>
<tr class="odd">
<td>6</td>
<td>9</td>
<td>11</td>
<td>16</td>
</tr>
</tbody>
</table>
<div id="recursive-forecasts" class="section level2">
<h2>Recursive forecasts</h2>
<p>Given a model trained with the previous dataset, the next future
value of the series is predicted as <span class="math inline">\(f(Lag4,
Lag2, Lag1)\)</span>, where <span class="math inline">\(f\)</span> is
the regression function and <span class="math inline">\(Lag4\)</span>,
<span class="math inline">\(Lag2\)</span> and <span class="math inline">\(Lag1\)</span> are the fourth, second and first
lagged values of the next future value. So, the next future value of
series <span class="math inline">\(t\)</span> is predicted as <span class="math inline">\(f(7, 11, 16)\)</span>, producing a value that will
be called <span class="math inline">\(F1\)</span>.</p>
<p>Suppose that the <em>forecast horizon</em> (the number of future
values to be forecast into the future) is greater than 1. In the case
that the regression function only predicts the next future value of the
series, a recursive approach can be applied to forecast all the future
values in the forecast horizon. Using a recursive approach, the
regression function is applied recursively until all steps ahead values
are forecast. For instance, following the previous example, suppose that
the forecast horizon is 3. As we have explained, to forecast the next
future value of the series (one-step ahead) the regression function is
fed with the vector <span class="math inline">\([7, 11, 16]\)</span>,
producing <span class="math inline">\(F1\)</span>. To forecast the
two-steps ahead value the regression function is fed with the vector
<span class="math inline">\([9, 16, F1]\)</span>. The forecast for the
one-step ahead value, <span class="math inline">\(F1\)</span>, is used
as the first lag for the two-steps ahead value, because the actual value
is unknown. Finally, to predict the three-steps ahead value the
regression function is fed with the vector [<span class="math inline">\(11, F1, F2]\)</span>. This example of recursive
forecast is summarized in the following table:</p>
<table>
<thead>
<tr class="header">
<th>Steps ahead</th>
<th>Autoregressive values</th>
<th>Forecast</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>7, 11, 16</td>
<td>F1</td>
</tr>
<tr class="even">
<td>2</td>
<td>9, 16, F1</td>
<td>F2</td>
</tr>
<tr class="odd">
<td>3</td>
<td>11, F1, F2</td>
<td>F3</td>
</tr>
</tbody>
</table>
<p>The recursive approach for forecasting several values into the future
is applied in classical statistical models such as ARIMA or exponential
smoothing.</p>
</div>
</div>
<div id="the-utsf-package" class="section level1">
<h1>The utsf package</h1>
<p>The <strong>utsf</strong> package makes it easy the use of classical
regression models for univariate time series forecasting, employing the
autoregressive approach and the recursive prediction strategy explained
in the previous section. All the supported models are applied using an
uniform interface:</p>
<ul>
<li>the <code>create_model()</code> function to build the forecasting
model, and</li>
<li>the <code>forecast()</code> function for using the model to predict
future values.</li>
</ul>
<p>Let us see an example in which a regression tree model is used to
forecast the next future values of a time series:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> <span class="st">&quot;rt&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">12</span>)</span></code></pre></div>
<p>In this example, an autoregressive tree model
(<code>method = &quot;rt&quot;</code>, Regression Tree) is trained using the
historical values of the <code>AirPassengers</code> time series and a
forecast for its 12 next future values (<code>h = 12</code>) is done.
The <code>create_model()</code> function returns an S3 object of class
<code>utsf</code> with information about the trained model. The
information about the forecast is included in the object returned by the
<code>forecast()</code> function, as a component named <code>pred</code>
of class <code>ts</code> (a time series):</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>f<span class="sc">$</span>pred</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co">#&gt;           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co">#&gt; 1961 460.2980 428.4915 467.0304 496.9833 499.9819 554.7891 627.5849 628.0503</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co">#&gt;           Sep      Oct      Nov      Dec</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co">#&gt; 1961 533.2803 482.4221 448.7926 453.6920</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>The training set used to fit the model is built from the historical
values of the time series using the autoregressive approach explained in
the previous section. The <code>lags</code> parameter of the
<code>create_model()</code> function is used to specify the
autoregressive lags. In the example: <code>lags = 1:12</code>, so a
target is a function of its 12 previous values. Next, we consult the
first targets (and their associated features) with which the regression
model has been trained:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">head</span>(m<span class="sc">$</span>targets)  <span class="co"># first targets</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co">#&gt; [1] -11.6666667  -0.9166667  13.4166667   6.6666667  -3.8333333  19.8333333</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="fu">head</span>(m<span class="sc">$</span>features) <span class="co"># and its associated features</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co">#&gt;         Lag12     Lag11     Lag10      Lag9       Lag8       Lag7       Lag6</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">#&gt; 1 -14.6666667 -8.666667  5.333333  2.333333  -5.666667   8.333333  21.333333</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">#&gt; 2  -8.9166667  5.083333  2.083333 -5.916667   8.083333  21.083333  21.083333</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co">#&gt; 3   4.4166667  1.416667 -6.583333  7.416667  20.416667  20.416667   8.416667</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co">#&gt; 4   0.6666667 -7.333333  6.666667 19.666667  19.666667   7.666667  -9.333333</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co">#&gt; 5  -7.8333333  6.166667 19.166667 19.166667   7.166667  -9.833333 -24.833333</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co">#&gt; 6   5.8333333 18.833333 18.833333  6.833333 -10.166667 -25.166667 -11.166667</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="co">#&gt;         Lag5       Lag4       Lag3       Lag2       Lag1</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a><span class="co">#&gt; 1  21.333333   9.333333  -7.666667 -22.666667  -8.666667</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a><span class="co">#&gt; 2   9.083333  -7.916667 -22.916667  -8.916667 -11.916667</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="co">#&gt; 3  -8.583333 -23.583333  -9.583333 -12.583333  -1.583333</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a><span class="co">#&gt; 4 -24.333333 -10.333333 -13.333333  -2.333333  12.666667</span></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a><span class="co">#&gt; 5 -10.833333 -13.833333  -2.833333  12.166667   6.166667</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a><span class="co">#&gt; 6 -14.166667  -3.166667  11.833333   5.833333  -4.166667</span></span></code></pre></div>
<p>The curious reader might have noticed that the features and targets
are not on the same scale as the original time series. This is because,
by default, a transformation is applied to the examples of the training
set. This transformation will be explained later.</p>
<p>Let us see the training set associated with the example of the
previous section:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>, <span class="dv">16</span>))</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">create_model</span>(t, <span class="at">lags =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>), <span class="at">trend =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="fu">cbind</span>(out<span class="sc">$</span>features, <span class="at">Target =</span> out<span class="sc">$</span>targets)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co">#&gt;   Lag4 Lag2 Lag1 Target</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">#&gt; 1    1    6    7      9</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">#&gt; 2    3    7    9     11</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">#&gt; 3    6    9   11     16</span></span></code></pre></div>
<p>Here, no transformation has been applied
(<code>trend = &quot;none&quot;</code>).</p>
</div>
<div id="prediction-intervals" class="section level1">
<h1>Prediction intervals</h1>
<p>Prediction intervals for a forecast can be computed:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(USAccDeaths, <span class="at">method =</span> <span class="st">&quot;mt&quot;</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">12</span>, <span class="at">PI =</span> <span class="cn">TRUE</span>, <span class="at">level =</span> <span class="dv">90</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>f</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co">#&gt;          Point Forecast    Lo 90     Hi 90</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#&gt; Jan 1979       8162.724 7612.520  8703.023</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">#&gt; Feb 1979       7185.788 6597.051  7744.887</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">#&gt; Mar 1979       7475.744 6927.619  8020.395</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt; Apr 1979       7836.936 7217.843  8420.431</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co">#&gt; May 1979       8570.632 8028.427  9133.970</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co">#&gt; Jun 1979       9018.691 8408.565  9583.103</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="co">#&gt; Jul 1979       9865.224 9256.995 10451.958</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="co">#&gt; Aug 1979       9695.409 9087.325 10267.034</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a><span class="co">#&gt; Sep 1979       9160.569 8573.240  9767.617</span></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="co">#&gt; Oct 1979       8962.662 8382.609  9518.964</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="co">#&gt; Nov 1979       8606.452 7997.011  9175.178</span></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a><span class="co">#&gt; Dec 1979       8899.133 8350.682  9465.557</span></span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>Prediction intervals are calculated following the guidelines in (<a href="https://otexts.com/fpp3/nnetar.html#prediction-intervals-5" class="uri">https://otexts.com/fpp3/nnetar.html#prediction-intervals-5</a>).
Random errors are assumed to follow a normal distribution. In the
example, a 90% prediction interval (<code>level = 90</code>) has been
computed.</p>
</div>
<div id="supported-models" class="section level1">
<h1>Supported models</h1>
<p>The <code>create_model()</code> and <code>forecast()</code> functions
provide a common interface to applying an autoregressive approach for
time series forecasting using different regression models. These models
are implemented in several R packages. Currently, our project is mainly
focused on regression tree models, supporting the following
approaches:</p>
<ul>
<li>k-nearest neighbors: In this case no model is trained and the
function <code>FNN::knn.reg()</code> is used, as regression function, to
recursively predict the future values of the time series.</li>
<li>Linear models: The model is trained using the function
<code>stats::lm()</code> and its associated method
<code>stats::predict.lm()</code> is applied recursively for the
forecasts, i.e., as regression function.</li>
<li>Regression trees: The model is trained using the function
<code>rpart::rpart()</code> and its associated method
<code>rpart::predict.rpart()</code> is used for the forecasts.</li>
<li>Model trees: The model is trained with the function
<code>Cubist::cubist()</code> and its associated method
<code>Cubist::predict.cubist()</code> is used for predictions.</li>
<li>Bagging: The model is trained with the function
<code>ipred::bagging()</code> and its associated method
<code>ipred::predict.regbagg()</code> is used for forecasting.</li>
<li>Random forest: The model is trained with the function
<code>ranger::ranger()</code> and its associated method
<code>ranger::predict.ranger()</code> is used for predictions.</li>
</ul>
<p>The S3 object of class <code>utsf</code> returned by the
<code>create_model()</code> function contains a component with the
trained autoregressive model:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(fdeaths, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> <span class="st">&quot;rt&quot;</span>)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>m<span class="sc">$</span>model</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co">#&gt; n= 60 </span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co">#&gt; node), split, n, deviance, yval</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="co">#&gt;       * denotes terminal node</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="co">#&gt; 1) root 60 1967124.00   -6.465278  </span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="co">#&gt;   2) Lag12&lt; 73 38  212851.90 -124.414500  </span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co">#&gt;     4) Lag6&gt;=-66.45833 30   57355.07 -153.847200  </span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="co">#&gt;       8) Lag12&lt; -170.7083 10   13293.09 -195.991700 *</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co">#&gt;       9) Lag12&gt;=-170.7083 20   17419.67 -132.775000 *</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="co">#&gt;     5) Lag6&lt; -66.45833 8   32051.01  -14.041670 *</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="co">#&gt;   3) Lag12&gt;=73 22  312482.00  197.265200  </span></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="co">#&gt;     6) Lag5&gt;=-131.7917 7   24738.12  114.500000 *</span></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a><span class="co">#&gt;     7) Lag5&lt; -131.7917 15  217416.40  235.888900 *</span></span></code></pre></div>
<p>In this case, the model is the result of training a regression tree
using the function <code>rpart::rpart()</code> with the training set
consisting of the features <code>m$features</code> and targets
<code>m$targets</code>. Once the model is trained, the
<code>rpart::predict.rpart()</code> function can be used recursively to
forecast the future values of the time series using the
<code>forecast()</code> function.</p>
</div>
<div id="using-your-own-models" class="section level1">
<h1>Using your own models</h1>
<p>An interesting feature of the <strong>utsf</strong> package is its
extensibility. Apart from the models directly supported by the package,
you can use the facilities of the package to do autoregressive time
series forecasting using your own regression models. Thus, your models
can benefit from the features implemented in the package, such as the
building of the training set, the implementation of recursive forecasts,
pre-processings, the estimation of forecast accuracy or parameter
tuning.</p>
<p>To apply your own regression model you have to use the
<code>method</code> parameter of the <code>create_model()</code>
function, providing as argument a function that is able to train your
model. This function should return an object with the trained regression
model. The function must have three input parameters:</p>
<ul>
<li><code>X</code>: it is a data frame with the features of the training
examples. This data frame is built from the time series taking into
account the autoregressive lags as explained in a previous section. This
is the same object as the <code>features</code> component of the object
returned by the <code>create_model()</code> function.</li>
<li><code>y</code>: a vector with the targets of the training examples.
It is built as explained in a previous section. It is the same object as
the <code>targets</code> component of the object returned by the
<code>create_model()</code> function.</li>
<li><code>param</code>: it is a list with additional arguments for
adjusting the behavior of the model. This parameter will not be used in
this section and will be explained in the next section.</li>
</ul>
<p>Furthermore, if the function that trains the model (the function
provided in the <code>method</code> parameter) returns a model of class
<code>model_class</code>, a method with the signature
<code>predict.model_class(object, new_value)</code> should be
implemented. This method uses your model to predict a new value, that
is, it is the regression function associated with the model. Let us
explain the parameters of this regression function:</p>
<ul>
<li><code>object</code>: it is the object of class
<code>model_class</code> returned by your function that creates the
model.</li>
<li><code>new_value</code>: it is a data frame with the same structure
as the <code>X</code> parameter of the function for building the model.
The <code>new_value</code> data frame has only one row, with the
features of the example to be predicted.</li>
</ul>
<p>Let us see several examples of how to use this functionality for
applying your ouw models for autoregressive time series forecasting
taking advantage of the capabilities of the <strong>utsf</strong>
package.</p>
<div id="example-1-k-nearest-neighbors" class="section level2">
<h2>Example 1: k-nearest neighbors</h2>
<p>The case of K-nearest neighbors is a bit special because it is a lazy
learner and no model is built. You only need to store the training set
and all the work is done by the regression function. Let us see a first
example in which we rely on the implementation of k-NN in the
<strong>FNN</strong> package:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Function to train the regression model</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co"># In this case (k-NN) just stores the training set</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>my_knn_model <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, param) {</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>  <span class="fu">structure</span>(<span class="fu">list</span>(<span class="at">X =</span> X, <span class="at">y =</span> y), <span class="at">class =</span> <span class="st">&quot;my_knn&quot;</span>)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>}</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co"># Function to predict a new example</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>predict.my_knn <span class="ot">&lt;-</span> <span class="cf">function</span>(object, new_value) {</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>  FNN<span class="sc">::</span><span class="fu">knn.reg</span>(<span class="at">train =</span> object<span class="sc">$</span>X, <span class="at">test =</span> new_value, <span class="at">y =</span> object<span class="sc">$</span>y)<span class="sc">$</span>pred</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>}</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> my_knn_model)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">12</span>)</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>f<span class="sc">$</span>pred</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="co">#&gt;           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="co">#&gt; 1961 455.9167 434.3264 480.7703 490.1678 506.1262 568.0534 640.6689 640.8636</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="co">#&gt;           Sep      Oct      Nov      Dec</span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a><span class="co">#&gt; 1961 549.5467 495.4255 441.6554 476.7934</span></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>The function that trains the model (<code>my_knn_model()</code>)
creates a “model” that only stores the training set. The regression
function (<code>predict.my_knn()</code>) takes advantage of the
<code>FNN::knn.reg()</code> function to look for the k-nearest neighbors
and compute their mean response value. The default number of neighbors
(3) of <code>FNN::knn.reg()</code> is used. Later, we will modify this
example so that the user can select the <span class="math inline">\(k\)</span> value.</p>
<p>The k-nearest neighbors algorithm is so simple that it can be easily
implemented without using functionality from any R package:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Function to train the regression model</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>my_knn_model2 <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, param) {</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>  <span class="fu">structure</span>(<span class="fu">list</span>(<span class="at">X =</span> X, <span class="at">y =</span> y), <span class="at">class =</span> <span class="st">&quot;my_knn2&quot;</span>)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>}</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co"># Function to predict a new example</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>predict.my_knn2 <span class="ot">&lt;-</span> <span class="cf">function</span>(object, new_value) {</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="dv">3</span> <span class="co"># number of nearest neighbors</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>  distances <span class="ot">&lt;-</span> <span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(object<span class="sc">$</span>X), <span class="cf">function</span>(i) <span class="fu">sum</span>((object<span class="sc">$</span>X[i, ] <span class="sc">-</span> new_value)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>  k_nearest <span class="ot">&lt;-</span> <span class="fu">order</span>(distances)[<span class="dv">1</span><span class="sc">:</span>k]</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>  <span class="fu">mean</span>(object<span class="sc">$</span>y[k_nearest])</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>}</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> my_knn_model2)</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a><span class="fu">forecast</span>(m2, <span class="at">h =</span> <span class="dv">12</span>)<span class="sc">$</span>pred</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a><span class="co">#&gt;           Jan      Feb      Mar      Apr      May      Jun      Jul      Aug</span></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a><span class="co">#&gt; 1961 455.9167 434.3264 480.7703 490.1678 506.1262 568.0534 640.6689 640.8636</span></span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a><span class="co">#&gt;           Sep      Oct      Nov      Dec</span></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a><span class="co">#&gt; 1961 549.5467 495.4255 441.6554 476.7934</span></span></code></pre></div>
</div>
<div id="example-2-random-forest-and-neural-networks" class="section level2">
<h2>Example 2: random forest and neural networks</h2>
<p>The random forest algorithm is directly supported in the
<strong>utsf</strong> package, using the implementation of random
forests in the <code>ranger</code> package. Here, we are going to create
an autoregressive model based on the random forest model implemented in
the <code>RandomForest</code> package:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co">#&gt; randomForest 4.7-1.2</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co">#&gt; Type rfNews() to see new features/changes/bug fixes.</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co">#&gt; Adjuntando el paquete: &#39;randomForest&#39;</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">#&gt; The following object is masked from &#39;package:ggplot2&#39;:</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co">#&gt;     margin</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, param) { <span class="fu">randomForest</span>(<span class="at">x =</span> X, <span class="at">y =</span> y) }</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(USAccDeaths, <span class="at">method =</span> my_model)</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">12</span>)</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">print</span>(m<span class="sc">$</span>model)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co">#&gt;  randomForest(x = X, y = y) </span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="co">#&gt;                Type of random forest: regression</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co">#&gt;                      Number of trees: 500</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co">#&gt; No. of variables tried at each split: 4</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co">#&gt;           Mean of squared residuals: 191987.2</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a><span class="co">#&gt;                     % Var explained: 77.2</span></span></code></pre></div>
<p>The function that creates the model (<code>my_model()</code>) just
uses the <code>randomForest::randomForest()</code> function. This
function returns an S3 object of class <code>randomForest</code> with
the trained model. In this case, we have not implemented the regression
function, because the <code>predict.randomForest()</code> method does
exactly what we want.</p>
<p>As another example, we are going to use a neural network model
implemented in the <em>nnet</em> package:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, param) {</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>  <span class="fu">nnet</span>(<span class="at">x =</span> X, <span class="at">y =</span> y, <span class="at">size =</span> <span class="dv">5</span>, <span class="at">linout =</span> <span class="cn">TRUE</span>, <span class="at">trace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>}</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(USAccDeaths, <span class="at">method =</span> my_model)</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">12</span>)</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>In this case, the <code>nnet()</code> function returns an S3 object
of class <code>nnet</code>. Again, regression method associated with
this class, <code>predict.nnet()</code>, is what we need as regression
function. Because we are using neural networks, probably some
pre-processing would be needed to obtain more accurate predictions.</p>
</div>
<div id="example-3-extreme-gradient-boosting" class="section level2">
<h2>Example 3: Extreme gradient boosting</h2>
<p>In this case we are going to apply the extreme gradient boosting
model implemented in the <code>xgboost</code> package. We rely on the
<code>xgboost::xgboost()</code> function to build the model. This
function returns an object of class <code>xgb.Booster</code> with the
trained model. However, we cannot use the
<code>xgboost::predict.xgb.Booster()</code> regression function, because
the <code>newvalue</code> parameter of this function cannot be a data
frame. Let us see how we can get around this problem:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, param) {</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>  m <span class="ot">&lt;-</span> <span class="fu">xgboost</span>(<span class="at">data =</span> <span class="fu">as.matrix</span>(X), </span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>               <span class="at">label =</span> y, </span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>               <span class="at">nrounds =</span> <span class="dv">100</span>,</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>               <span class="at">verbose =</span> <span class="dv">0</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>  )</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>  <span class="fu">structure</span>(m, <span class="at">class =</span> <span class="st">&quot;my_model&quot;</span>)</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>}</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>predict.my_model <span class="ot">&lt;-</span> <span class="cf">function</span>(object, new_value) {</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>  <span class="fu">class</span>(object) <span class="ot">&lt;-</span> <span class="st">&quot;xgb.Booster&quot;</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>  <span class="fu">predict</span>(object, <span class="fu">as.matrix</span>(new_value))</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>}</span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(USAccDeaths, <span class="at">method =</span> my_model)</span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">12</span>)</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>The trick is that we change the class of the object (model) returned
by <code>xgboost()</code> to class <code>my_model</code>, so that we can
provide our own regression function (<code>predict.my_model()</code>).
In this function we change again the class of the model to use the
original regression function: <code>predict.xgb.Booster()</code>, but we
convert the <code>new_value</code> from a data frame to a matrix that is
a format expected by <code>predict.xgb.Booster()</code>.</p>
</div>
</div>
<div id="setting-the-parameters-of-the-regression-models" class="section level1">
<h1>Setting the parameters of the regression models</h1>
<p>Normally, a regression model can be adjusted using different
parameters. By default, the models supported by our package are set
using some specific parameters, usually the default values of the
functions used to train the models (these functions are listed in a
previous section). However, the user can select these parameters with
the <code>param</code> argument of the <code>create_model()</code>
function. The <code>param</code> argument must be a named list with the
names and values of the parameters to be set. Let us see an example:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># A bagging model set with default parameters</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> <span class="st">&quot;bagging&quot;</span>)</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="fu">length</span>(m<span class="sc">$</span>model<span class="sc">$</span>mtrees) <span class="co"># number of regression trees (25 by default)</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co">#&gt; [1] 25</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="co"># A bagging model set with 3 regression trees</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers,</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>                   <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>,</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>                   <span class="at">method =</span> <span class="st">&quot;bagging&quot;</span>,</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>                   <span class="at">param =</span> <span class="fu">list</span>(<span class="at">nbagg =</span> <span class="dv">3</span>)</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>)</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="fu">length</span>(m2<span class="sc">$</span>model<span class="sc">$</span>mtrees) <span class="co"># number of regression trees</span></span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a><span class="co">#&gt; [1] 3</span></span></code></pre></div>
<p>In the previous example, two bagging models (using regression trees)
are trained with the <code>create_model()</code> function. In the first
model the number of trees is 25, the default value of the function
<code>ipred::ipredbagg()</code> used to train the model. In the second
model the number of trees is set to 3. Of course, in order to set some
specific parameters the user must consult the parameters of the function
used internally by the <strong>utsf</strong> package to train the model:
in the example, <code>ipred::ipredbagg()</code>. In this case, the
<code>nbagg</code> parameter of the <code>ipred::ipredbagg()</code>
function is set to 3.</p>
<div id="setting-the-paramaters-of-a-regression-model-supplied-by-the-user" class="section level2">
<h2>Setting the paramaters of a regression model supplied by the
user</h2>
<p>When the regression model is provided by the user, it is also
possible to adjust its parameters. As explained previously, if you want
to use your own regression model you have to provide a function that
creates your model. This function has tree parameters:</p>
<ul>
<li><code>X</code>: to receive the training features</li>
<li><code>y</code>: to receive the targets</li>
<li><code>param</code>: in this parameter the arguments for adjusting
the model are received.</li>
</ul>
<p>The <code>param</code> parameter receives a named list with the names
and values of the arguments of the model to be adjusted. This list is
the same list that the user pass to the <code>param</code> parameter of
the <code>create_model()</code> function.</p>
<p>Let us see some example of how to pass arguments to some of the
regression models implemented in the previous section.</p>
<div id="example-1-k-nearest-neighbors-1" class="section level3">
<h3>Example 1: k-nearest neighbors</h3>
<p>In this case the model can be adjusted specifying the <span class="math inline">\(k\)</span> value. The function provided to train
the model can be tuned with an argument named <code>k</code> with the
number of nearest neighbors:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># Function to train the model</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>my_knn_model <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, param) {</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="cf">if</span> (<span class="st">&quot;k&quot;</span> <span class="sc">%in%</span> <span class="fu">names</span>(param)) param<span class="sc">$</span>k <span class="cf">else</span> <span class="dv">3</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>  <span class="fu">structure</span>(<span class="fu">list</span>(<span class="at">X =</span> X, <span class="at">y =</span> y, <span class="at">k =</span> k), <span class="at">class =</span> <span class="st">&quot;my_knn&quot;</span>)</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>}</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a><span class="co"># Regression function for object of class my_knn</span></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>predict.my_knn <span class="ot">&lt;-</span> <span class="cf">function</span>(object, new_value) {</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>  FNN<span class="sc">::</span><span class="fu">knn.reg</span>(<span class="at">train =</span> object<span class="sc">$</span>X, <span class="at">test =</span> new_value,</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>               <span class="at">y =</span> object<span class="sc">$</span>y, <span class="at">k =</span> object<span class="sc">$</span>k)<span class="sc">$</span>pred</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>}</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a><span class="co"># The model is trained with default parameters (k = 3)</span></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>,  <span class="at">method =</span> my_knn_model)</span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a><span class="fu">print</span>(m<span class="sc">$</span>model<span class="sc">$</span>k)</span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a><span class="co">#&gt; [1] 3</span></span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a><span class="co"># The model is trained with k = 5</span></span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">method =</span> my_knn_model, <span class="at">param =</span> <span class="fu">list</span>(<span class="at">k =</span> <span class="dv">5</span>))</span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a><span class="fu">print</span>(m2<span class="sc">$</span>model<span class="sc">$</span>k)</span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a><span class="co">#&gt; [1] 5</span></span></code></pre></div>
<p>The list provided as argument for the <code>param</code> parameter in
the <code>create_model()</code> function is passed as argument to the
<code>param</code> parameter of the function that trains the model
(<code>my_knn_model()</code>). In this case, in the second call to
<code>create_model()</code> the argument of the <code>param</code>
parameter, <code>list(k = 5)</code>, is passed as argument for the
<code>param</code> parameter of the <code>my_knn_model()</code>
function.</p>
</div>
<div id="example-2-random-forest" class="section level3">
<h3>Example 2: random forest</h3>
<p>As another example, suppose that we create a random forest model
using the functionality in the <em>randomForest</em> package. By
default, we will use the default parameters of the
<code>randomForest::randomForest()</code> function to build the model,
save for the number of trees (it will be set to 200). However, the user
can train the model with other values:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, param) {</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>    args <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">x =</span> X, <span class="at">y =</span> y, <span class="at">ntree =</span> <span class="dv">200</span>) <span class="co"># default parameters</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>    args <span class="ot">&lt;-</span> args[<span class="sc">!</span>(<span class="fu">names</span>(args) <span class="sc">%in%</span> <span class="fu">names</span>(param))]</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>    args <span class="ot">&lt;-</span> <span class="fu">c</span>(args, param)</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>    <span class="fu">do.call</span>(randomForest<span class="sc">::</span>randomForest, <span class="at">args =</span> args)</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>}</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="co"># The random forest is built with our default parameters</span></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(USAccDeaths, <span class="at">method =</span> my_model)</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="fu">print</span>(m<span class="sc">$</span>model<span class="sc">$</span>ntree)</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a><span class="co">#&gt; [1] 200</span></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a><span class="fu">print</span>(m<span class="sc">$</span>model<span class="sc">$</span>mtry)</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="co">#&gt; [1] 4</span></span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a><span class="co"># The random forest is built with ntree = 400 and mtry = 6</span></span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(USAccDeaths, <span class="at">method =</span> my_model, </span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a>                  <span class="at">param =</span> <span class="fu">list</span>(<span class="at">ntree =</span> <span class="dv">400</span>, <span class="at">mtry =</span> <span class="dv">6</span>))</span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a><span class="fu">print</span>(m<span class="sc">$</span>model<span class="sc">$</span>ntree)</span>
<span id="cb16-18"><a href="#cb16-18" tabindex="-1"></a><span class="co">#&gt; [1] 400</span></span>
<span id="cb16-19"><a href="#cb16-19" tabindex="-1"></a><span class="fu">print</span>(m<span class="sc">$</span>model<span class="sc">$</span>mtry)</span>
<span id="cb16-20"><a href="#cb16-20" tabindex="-1"></a><span class="co">#&gt; [1] 6</span></span></code></pre></div>
</div>
</div>
</div>
<div id="estimating-forecast-accuracy" class="section level1">
<h1>Estimating forecast accuracy</h1>
<p>This section explains how to estimate the forecast accuracy of a
regression model predicting a time series with the <strong>utsf</strong>
package. Let us see an example:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(UKgas, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">type =</span> <span class="st">&quot;normal&quot;</span>, <span class="at">size =</span> <span class="dv">8</span>)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>r<span class="sc">$</span>per_horizon</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="co">#&gt;       Horizon 1 Horizon 2 Horizon 3 Horizon 4</span></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a><span class="co">#&gt; MAE   40.956667 37.205000 42.730417 51.424167</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="co">#&gt; MAPE   4.118140  5.030128  7.468098  7.434864</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a><span class="co">#&gt; sMAPE  4.261377  5.208551  7.814417  7.732037</span></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a><span class="co">#&gt; RMSE  58.920772 47.660996 49.733955 55.023038</span></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a>r<span class="sc">$</span>global</span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a><span class="co">#&gt;       MAE      MAPE     sMAPE      RMSE </span></span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a><span class="co">#&gt; 43.079063  6.012808  6.254095 52.834690</span></span></code></pre></div>
<p>To assess the forecast accuracy of a model you should use the
<code>efa()</code> function on the model. In this case, the forecasting
method is a K-nearest neighbors algorithm (<code>method = &quot;knn&quot;</code>),
with autoregressive lags 1 to 4, applied on the <code>UKgas</code> time
series. An estimation of its forecast accuracy on the series for a
forecasting horizon of 4 (<code>h = 4</code>) is obtained according to
different forecast accuracy measures. The <code>efa()</code> function
returns a list with two components. The component named
<code>per_horizon</code> contains the forecast accuracy estimations per
forecasting horizon. The component named <code>global</code> is computed
as the means of the rows of the <code>per_horizon</code> component.
Currently, the following forecast accuracy measures are computed:</p>
<ul>
<li>MAE: mean absolute error</li>
<li>MAPE: mean absolute percentage error</li>
<li>sMAPE: symmetric MAPE</li>
<li>RMSE: root mean squared error</li>
</ul>
<p>Next, we describe how the forecasting accuracy measures are computed
for a forecasting horizon <span class="math inline">\(h\)</span> (<span class="math inline">\(y_t\)</span> and <span class="math inline">\(\hat{y}_t\)</span> are the actual future value and
its forecast for horizon <span class="math inline">\(t\)</span>
respectively):</p>
<p><span class="math display">\[
MAE = \frac{1}{h}\sum_{t=1}^{h} |y_t-\hat{y}_t|
\]</span></p>
<p><span class="math display">\[
MAPE = \frac{1}{h}\sum_{t=1}^{h} 100\frac{|y_t-\hat{y}_t|}{y_t}
\]</span> <span class="math display">\[
sMAPE = \frac{1}{h}\sum_{t=1}^{h}
200\frac{\left|y_{t}-\hat{y}_{t}\right|}{|y_t|+|\hat{y}_t|}
\]</span></p>
<p><span class="math display">\[
RMSE = \sqrt{\frac{1}{h}\sum_{t=1}^{h} (y_t-\hat{y}_t)^2}
\]</span></p>
<p>The estimation of forecast accuracy is done with the well-known
rolling origin evaluation. This technique builds several training and
test sets from the series, as shown below for a forecasting horizon of
4:</p>
<p><img role="img" src="data:image/png;base64,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" width="85%" /></p>
<p>In this case, the last nine observations of the series are used to
build the test sets. Six models are trained using the different training
sets and their forecasts are compared to their corresponding test sets.
Thus, the estimation of the forecast error for every forecasting horizon
is based on six errors (it is computed as the mean).</p>
<p>You can specify how many of the last observations of the series are
used to build the test sets with the <code>size</code> and
<code>prop</code> parameters. For example:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(UKgas, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>)</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="co"># Use the last 9 observations of the series to build test sets</span></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>r1 <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">type =</span> <span class="st">&quot;normal&quot;</span>, <span class="at">size =</span> <span class="dv">9</span>)</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="co"># Use the last 20% observations of the series to build test sets</span></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>r2 <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">type =</span> <span class="st">&quot;normal&quot;</span>, <span class="at">prop =</span> <span class="fl">0.2</span>)</span></code></pre></div>
<p>If the series is short, the training sets might be too small to fit a
meaningful model. In that case, a special rolling origin evaluation can
be done, setting parameter <code>type</code> to
<code>&quot;minimum&quot;</code>:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(UKgas, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>)</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">type =</span> <span class="st">&quot;minimum&quot;</span>)</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>r<span class="sc">$</span>per_horizon</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a><span class="co">#&gt;       Horizon 1 Horizon 2 Horizon 3 Horizon 4</span></span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a><span class="co">#&gt; MAE   47.893750 44.934722 44.918229 26.961198</span></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a><span class="co">#&gt; MAPE   5.745458  6.757300  8.250563  3.444200</span></span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a><span class="co">#&gt; sMAPE  5.761843  6.791762  8.329877  3.385892</span></span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a><span class="co">#&gt; RMSE  56.558584 52.858868 46.912818 26.961198</span></span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>r<span class="sc">$</span>global</span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a><span class="co">#&gt;       MAE      MAPE     sMAPE      RMSE </span></span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a><span class="co">#&gt; 41.176975  6.049380  6.067343 45.822867</span></span></code></pre></div>
<p>When this option is chosen, the last <code>h</code> observations (in
the example 4) are used to build the training sets as is shown below for
<code>h = 4</code>:</p>
<p><img role="img" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmoAAACMCAYAAADMUIXJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAECQAABAkAfxIj5wAAAtXSURBVHhe7d29chrJGgbgnnMtsIFrrwAibyacbOTAiTMIIdnM4clOgkKRbeLA0SaGzI7EFbgcGPK9DM40M0Ig/loSklrS81TN7oC++RhYqni3uxmKRSkAAJCd/9T/BgAgM4IaAECmBDUAgEwJagAAmRLUAAAyJagBAGRKUAMAyJSgBgCQKUENACBTghoAQKYENQCATAlqAACZEtQAADJVLEr1/oaiqHf2WD/qUG1qXaRnRc/d9KzouZ+eldSe4fORph/Wig/VptZFd+kJr5gRNQCATAlqAACZEtQAADJ15zVqADw/3759r/dCePvvH/VehqxRgyVfJqjpWdFzPz0reu72HHv6MgHkz9QnAECmBDUAgEztnfoEAOBpGVEDAMiUoAYAkClBDQAgU4IaAECmBDUAgEwJagAAmRLUAAAyJagBAGRKUAMAyJSgBgCQKUENACBTghoAQKYENQCATBWLUr0PABxQFEW9B/eXEsEENQBIFIOaj01OIfW9ZOoTACBTghoAQKYENQCATAlqAACZEtQAADIlqAEAZEpQAwDIlKAGAJApQQ0AIFOCGgBApgQ1AIBMCWoAAJna+6PsRVHv7LF+1KHa1LpIz4qeu+lZ0XM/PSsP0TN8PlD8Ya3wUF2UWrtelxE/ys6p+FF2AOCw+XnotXthUt+8v3k4bxehaJ+Xe7dx1+MycvLXsiKoAcAjiaOYh7bHNv/6JYym9Q3u5aFeS0ENADiRRuhfLsLisl/u3cZdj3v57hzUUv8PILUuSq1NrYtSa1ProtTa1LootTa1LkqtTa2LUmtT66LU2tS6KLU2tS5KrU2ti1JrU+ui1NrUuii1NrUuSq1NrYtSa1ProtTa1LootTa1LkqtTa2Lvn//vtoOimvNrrZjblPLA6qmGpuDOAQ0Cp3yDdE+j5OO9RRkbxLm5+3yfVLuF70wqecj55NeaMe/L++PWzv0lsdduTmFeX17MjlfO/ZUx1WW57VxTpPV8zisfJze1fOsj716suvmk9BbnUP5WsUpzlVZda7br+Vp3DmoxfVvV9shqXVRam1qXZRam1oXpdam1kWptal1UWptal2UWptaF6XWptZFqbWpdVFqbWpdlFqbWhel1qbWRam1qXVRam1qXZRam1oXpdam1kWptal1UWptal309u3b1XZQXPh/tR1zm1qezo//ho/L4FFqvQnNRhlHyuDW7IzCdGN6bxpGg2YZbuqb+0wHodMZrB17uuNW51Xfrmo64er094sBqxkGG/OV5bGdG+c1L4Nis7MxrTmdloGs2Q4nzGN7mfoEgHsoivTtmF3HHNvupppqnA1b5X43jMvkftlfm3SMyWg4KwP91XTkPHz9EpNKWTsr74v3x202DLHD6J9jiavUHYdZfVz1uKc4bhL+t0xkrTAc1+c7G4e67LD51xCfUmut//bzKcPcxzIolvd2r/rH8xjHumkY/C/WHXkt76t8QAAgwX0/NjfHNLe3x1aGi/Jxu4syXNRmizJv3Lhv02w2W4zHw8Ww212U0aSsLbfuVXV9fGtY7q3d3uo3XnRPcdy4u3z81rA6amU2rM5t1X+Hq5pWa9EdDhfj8nltqWu2+pduvnbbr+Vhqe8lI2oAwKY43VnvrsQpwKIIzWZzOR05GK1PNx6x1a8Z3sQBqGOOHDf/9aP8Zyu8f3djBKvxLrw/1r/RD5/K1BdHD0eDQeiUz2u5/qx3fr3+bPZz+Ryng+pv61u1Ju1H+PXA05+CGgBwxCT0mnEKME4VdsNwOA7j8SzMFuMQs85zdXZRTWN210LddBRD2+mvh3ZXghoAPJLtyc7NLVvzXyGOXXXHi3B5cRH6/bNwdtYIjfr+p9L47ffyn9Pw5euNYa16/VmKxlk/XMRLg5T/AWZxfdsyeY7Ccpla881yzVp83vHv29tlOOVytF0ENQB41dKn7+Ii+1VpvGTFcqF96cev6/sf09mfyxG96eBjOL++hkj9BYAjJr1qqvP8+jk1Gs3w23JutRXexDnXegp11Glf94/iYywv13Fz5O30U6GCGgC8atMwaB659tfVmq9RJzSv1mnduGTF0zgLfw3jiZXPoVOvIyvP6/ilOUpnfy2/HTodrD2nohk68eDW+1Ate2uEfrWQ7br/2mO0hn+VZ7Au4bW8JUENAF6pRv/Tan3W9OfswKhYGVj+Hm+s5Qqt7vKSGONljvkZZtW9j67Rvwyz8iSuTy1eSmOYsHYuXlZjFoabT6q6XMf6LyScXSwv27FZVl2uY/0yHOmv5e0UizjJCgAcFUdTfGw+B5PQKzrhx3AzTOUk9b1kRA0AeJ7qS4YUvaufnormYdLrhFG59/tveYa02zCiBgCJjKjlpv4ZqF1r0lrDzSnMzBhRAwBeuMR1Zs+YETUASGREjVMxogYA8MwJagAAmRLUAAAyJagBwGs1Pw+99gP+APlD99/lKR7zAQlqAPBYPheHt0c2//rlQX8G6qH77/IUj/mQBDUAgEwJagDw6sQLxRahubxS7Ch0ihs/JD6fhF7593gJibi141Ti1o9Xlj167VVNUbRDb1V0pP+WQ73WHDyv2z7m8yCoAQDX4s8yNTsb04fTaRl8mu1wnXtiKGqGwcYc4zSMOs0yYNU3kyX2Sjqvl8cFbwEgURzF2frYfIK1ZRs+3P1jfH7eDs3B72G8uAhn1T1VaJq2Qnf8d7g4q67tP5+ch4+dQZh2x2FxUVYuQ9MglEXh7/L2sqq+b1WzvOtm/x2SeiWeV7wv5TEzsPO9tIOgBgCJUj9c9zoW6u4Ruu5iK9RchabhLFz2N3+AaaP2Kki1yuD0/n348927cNbYrI9uE9QO9ko9rx23c5X6XjL1CQBUZj9DnFmcDprLILG+VWu/foRfcZqx0Q+furFwGkaDQeg0q/p273zHWrYjUnqlntcLJKgBwGOJI2aHtmfk7GIRZuNhWP899OkoBq3bX8PslL1eGkENAKg034SYlbrjxXJabnu7DOszj42zfri4rP42m43DMI6MhVH45w7p6mCvW57XSyKoAcCrtjZt2HgX3peJaNRph/P1Ocz5ZHnpi6KoR7gmveW0Y/t8ElaHNprhtzcxTrXCm2Z1X+XItGRKr9TzWnlBU6FlEgUAEry0j83ZsLV8TnFrDWfVnePu6r6b26pmMVsMW7trQmtY/rWu2tV/S1qvtPNKfcynF88vhRE1AHilGv1Pq3Vh05+zakTr7CKUaWdjvViI38gcr3/jshH6l7Mw3CwKre44zC771SU2Sjv7b0nrlXZeqY/5fOy9PEdx5BvE60cdqk2ti/Ss6LmbnhU999Oz8pQ9b3X5iUO1mS6sj1N0ez424VZS30tG1AAAMiWoAQBkSlADAMjUndeoAUD07dv3ei+Et//+Ue/dkzVqvHCp7yVfJqjpWdFzPz0reu6mZ82XCSCJLxMAADxzghoAQKb2Tn0CAJtMfXIqpj4BAJ45QQ0AIFOCGgBApqxRA4BEcV0RnEpKBBPUAAAyZeoTACBTghoAQKYENQCATAlqAACZEtQAADIlqAEAZEpQAwDIlKAGAJApQQ0AIFOCGgBApgQ1AIBMCWoAAJkS1AAAMiWoAQBkSlADAMiUoAYAkClBDQAgU4IaAECmBDUAgEwJagAAmRLUAAAyJagBAGSqWJTq/Q1FUe/ssX7UodrUukjPip676VnRcz89K8+lZ/h8oPjDeiG8XkbUAAAyJagBAGRKUAMAyNSd16gBwG19+/a93gvh7b9/1Hs7WKMGS75MUNOzoud+elb03E3Pym16+jIBHGfqEwAgU4IaAECm9k59AgDwtIyoAQBkSlADAMiUoAYAkClBDQAgU4IaAECmBDUAgEwJagAAmRLUAAAyJagBAGRKUAMAyFII/wdJqanFVhpBhgAAAABJRU5ErkJggg==" width="85%" /></p>
<p>In this case, the estimated forecast error for horizon 1 is based on
4 errors, for horizon 2 is based on 3 errors, for horizon 3 on 2 errors
and for horizon 4 on 1 error.</p>
<p>The <code>efa()</code> function also returns the test sets (and the
predictions associated with them) used when assessing the forecast
accuracy:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>timeS <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(timeS, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">method =</span> <span class="st">&quot;mt&quot;</span>)</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">5</span>, <span class="at">size =</span> <span class="dv">7</span>)</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>r<span class="sc">$</span>test_sets</span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="co">#&gt;      h=1 h=2 h=3 h=4 h=5</span></span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a><span class="co">#&gt; [1,]  19  20  21  22  23</span></span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a><span class="co">#&gt; [2,]  20  21  22  23  24</span></span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a><span class="co">#&gt; [3,]  21  22  23  24  25</span></span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a>r<span class="sc">$</span>predictions</span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a><span class="co">#&gt;      h=1 h=2 h=3 h=4 h=5</span></span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a><span class="co">#&gt; [1,]  19  20  21  22  23</span></span>
<span id="cb20-12"><a href="#cb20-12" tabindex="-1"></a><span class="co">#&gt; [2,]  20  21  22  23  24</span></span>
<span id="cb20-13"><a href="#cb20-13" tabindex="-1"></a><span class="co">#&gt; [3,]  21  22  23  24  25</span></span></code></pre></div>
<p>Each row in these tables represent a test set or prediction. Let us
see the test sets when the “minimum” evaluation is done:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>timeS <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">25</span>)</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(timeS, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">method =</span> <span class="st">&quot;mt&quot;</span>)</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">efa</span>(m, <span class="at">h =</span> <span class="dv">3</span>, <span class="at">type =</span> <span class="st">&quot;minimum&quot;</span>)</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>r<span class="sc">$</span>test_sets</span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a><span class="co">#&gt;      [,1] [,2] [,3]</span></span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a><span class="co">#&gt; [1,]   25   NA   NA</span></span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a><span class="co">#&gt; [2,]   24   25   NA</span></span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a><span class="co">#&gt; [3,]   23   24   25</span></span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a>r<span class="sc">$</span>predictions</span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a><span class="co">#&gt;      [,1] [,2] [,3]</span></span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a><span class="co">#&gt; [1,]   25   NA   NA</span></span>
<span id="cb21-12"><a href="#cb21-12" tabindex="-1"></a><span class="co">#&gt; [2,]   24   25   NA</span></span>
<span id="cb21-13"><a href="#cb21-13" tabindex="-1"></a><span class="co">#&gt; [3,]   23   24   25</span></span></code></pre></div>
</div>
<div id="parameter-tuning" class="section level1">
<h1>Parameter tuning</h1>
<p>Another useful feature of the <strong>utsf</strong> package is
parameter tuning. The <code>tune_grid()</code> function allows you to
estimate the forecast accuracy of a model using different combinations
of parameters. Furthermore, the best combination of parameters is used
to train a model with all the historical values of the series and the
model is applied for forecasting the future values of the series. Let us
see an example:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(UKgas, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>)</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(m, <span class="at">h =</span> <span class="dv">4</span>, <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">k =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>), <span class="at">type =</span> <span class="st">&quot;normal&quot;</span>, <span class="at">size =</span> <span class="dv">8</span>)</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="co"># To see the estimated forecast accuracy with the different configurations</span></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>r<span class="sc">$</span>tuneGrid</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a><span class="co">#&gt;   k      MAE     MAPE    sMAPE     RMSE</span></span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a><span class="co">#&gt; 1 1 27.50551 4.195273 4.344649 38.72080</span></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a><span class="co">#&gt; 2 2 41.67751 5.782108 5.995799 50.67769</span></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a><span class="co">#&gt; 3 3 43.07906 6.012808 6.254095 52.83469</span></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a><span class="co">#&gt; 4 4 43.58916 6.206692 6.382526 55.14836</span></span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a><span class="co">#&gt; 5 5 46.03185 6.332209 6.503322 58.41501</span></span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a><span class="co">#&gt; 6 6 47.64410 6.441446 6.583134 62.46201</span></span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a><span class="co">#&gt; 7 7 48.95917 6.841679 6.886563 63.75997</span></span></code></pre></div>
<p>In this example, the <code>tuneGrid</code> parameter is used to
specify (using a data frame) the set of parameters to assess. The
forecast accuracy of the model for the different combinations of
parameters is estimated as explained in the previous section using the
last observations of the time series as validation set. The
<code>size</code> parameter is used to specify the size of the test set.
The <code>tuneGrid</code> component of the list returned by the
<code>tune_grid()</code> function contains the result of the estimation.
In this case, the k-nearest neighbors method using <span class="math inline">\(k=1\)</span> obtains the best results for all the
forecast accuracy measures. The best combination of parameters according
to RMSE is used to forecast the time series:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>r<span class="sc">$</span>best</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="co">#&gt; $k</span></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="co">#&gt; [1] 1</span></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>r<span class="sc">$</span>forecast</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a><span class="co">#&gt;           Qtr1      Qtr2      Qtr3      Qtr4</span></span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a><span class="co">#&gt; 1987 1217.9250  661.4063  388.1828  817.3785</span></span></code></pre></div>
<p>Let us plot the values of <span class="math inline">\(k\)</span>
against their estimated accuracy using RMSE:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="fu">plot</span>(r<span class="sc">$</span>tuneGrid<span class="sc">$</span>k, r<span class="sc">$</span>tuneGrid<span class="sc">$</span>RMSE, <span class="at">type =</span> <span class="st">&quot;o&quot;</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">xlab =</span> <span class="st">&quot;k (number of nearest neighbors)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;RMSE&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Estimated accuracy&quot;</span>)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>Let us now see an example in which more than one tuning parameter is
used. In this case we use a random forest model and three tuning
parameters:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(UKDriverDeaths, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>)</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(m, </span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a>               <span class="at">h =</span> <span class="dv">12</span>, </span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a>               <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">num.trees =</span> <span class="fu">c</span>(<span class="dv">200</span>, <span class="dv">500</span>), <span class="at">replace =</span> <span class="fu">c</span>(<span class="cn">TRUE</span>, <span class="cn">FALSE</span>), <span class="at">mtry =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">8</span>)),</span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a>               <span class="at">type =</span> <span class="st">&quot;normal&quot;</span>, </span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a>               <span class="at">size =</span> <span class="dv">12</span></span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a>)</span>
<span id="cb25-8"><a href="#cb25-8" tabindex="-1"></a>r<span class="sc">$</span>tuneGrid</span>
<span id="cb25-9"><a href="#cb25-9" tabindex="-1"></a><span class="co">#&gt;   num.trees replace mtry       MAE     MAPE    sMAPE      RMSE</span></span>
<span id="cb25-10"><a href="#cb25-10" tabindex="-1"></a><span class="co">#&gt; 1       200    TRUE    4  96.26832 6.464129 6.823281  96.26832</span></span>
<span id="cb25-11"><a href="#cb25-11" tabindex="-1"></a><span class="co">#&gt; 2       500    TRUE    4 105.72996 7.096997 7.511665 105.72996</span></span>
<span id="cb25-12"><a href="#cb25-12" tabindex="-1"></a><span class="co">#&gt; 3       200   FALSE    4 106.43686 7.124778 7.552159 106.43686</span></span>
<span id="cb25-13"><a href="#cb25-13" tabindex="-1"></a><span class="co">#&gt; 4       500   FALSE    4 105.40314 7.050568 7.464402 105.40314</span></span>
<span id="cb25-14"><a href="#cb25-14" tabindex="-1"></a><span class="co">#&gt; 5       200    TRUE    8 110.48042 7.462148 7.918964 110.48042</span></span>
<span id="cb25-15"><a href="#cb25-15" tabindex="-1"></a><span class="co">#&gt; 6       500    TRUE    8 106.66487 7.253687 7.673312 106.66487</span></span>
<span id="cb25-16"><a href="#cb25-16" tabindex="-1"></a><span class="co">#&gt; 7       200   FALSE    8 104.21562 7.099506 7.502311 104.21562</span></span>
<span id="cb25-17"><a href="#cb25-17" tabindex="-1"></a><span class="co">#&gt; 8       500   FALSE    8 106.62072 7.248104 7.661996 106.62072</span></span></code></pre></div>
</div>
<div id="preprocessings-and-transformations" class="section level1">
<h1>Preprocessings and transformations</h1>
<p>Sometimes, the forecast accuracy of a model can be improved by
applying some transformations and/or preprocessings to the time series
being forecast. Currently, the <strong>utsf</strong> package is focused
on preprocessings related to forecasting time series with a trend. This
is due to the fact that, at present, most of the models incorporated in
our package (such as regression trees and k-nearest neighbors) predict
averages of the targets in the training set (i.e., an average of
historical values of the series). In a trended series these averages are
probably outside the range of the future values of the series. Let us
see an example in which a trended series (the yearly revenue passenger
miles flown by commercial airlines in the United States) is forecast
using a random forest model:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(airmiles, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">trend =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>In this case, no preprocessing is applied for dealing with the trend
(<code>trend = &quot;none&quot;</code>). It can be observed how the forecast does
not capture the trending behavior of the series because regression tree
models predict averaged values of the training targets.</p>
<p>In the next subsections we explain how to deal with trended series
using three different transformations.</p>
<div id="differencing" class="section level2">
<h2>Differencing</h2>
<p>A common way of dealing with trended series is to transform the
original series taking first differences (computing the differences
between consecutive observations). Then, the model is trained with the
differenced series and the forecasts are back-transformed. Let us see an
example:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(airmiles, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">trend =</span> <span class="st">&quot;differences&quot;</span>, <span class="at">nfd =</span> <span class="dv">1</span>)</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>In this case, the <code>trend</code> parameter has been used to
specify first-order differences (<code>trend = &quot;differences&quot;</code>).
The order of first differences is specified with the <code>nfd</code>
parameter (it will be normally 1). It is also possible to specify the
value -1, in which case the order of differences is estimated using the
<code>ndiffs()</code> function from the <strong>forecast</strong>
package (in that case, the chosen order of first differences could be 0,
that is, no differences are applied).</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a><span class="co"># The order of first differences is estimated using the ndiffs function</span></span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(airmiles, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">trend =</span> <span class="st">&quot;differences&quot;</span>, <span class="at">nfd =</span> <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a><span class="co">#&gt; Registered S3 method overwritten by &#39;quantmod&#39;:</span></span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a><span class="co">#&gt;   method            from</span></span>
<span id="cb28-5"><a href="#cb28-5" tabindex="-1"></a><span class="co">#&gt;   as.zoo.data.frame zoo</span></span>
<span id="cb28-6"><a href="#cb28-6" tabindex="-1"></a>m<span class="sc">$</span>differences</span>
<span id="cb28-7"><a href="#cb28-7" tabindex="-1"></a><span class="co">#&gt; Order of first differences (selected automatically): 2</span></span></code></pre></div>
</div>
<div id="the-additive-transformation" class="section level2">
<h2>The additive transformation</h2>
<p>This transformation has been used to deal with trending series in
other packages, such as <strong>tsfknn</strong> or
<strong>tsfgrnn</strong>. The additive transformation works transforming
the targets of the training set as follows:</p>
<ul>
<li>The target associated with a vector of features is transformed by
subtracting from it the mean of its associated vector of features.</li>
<li>To back transform a prediction, the mean of the input vector is
added to it.</li>
</ul>
<p>It is easy to check how the training examples are modified by the
additive transformation using the API of the package. For example, let
us see the training examples of a model with no transformation:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a>timeS <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">12</span>))</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(timeS, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">trend =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a><span class="fu">cbind</span>(m<span class="sc">$</span>features, <span class="at">Targets =</span> m<span class="sc">$</span>targets)</span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a><span class="co">#&gt;   Lag2 Lag1 Targets</span></span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a><span class="co">#&gt; 1    1    3       7</span></span>
<span id="cb29-6"><a href="#cb29-6" tabindex="-1"></a><span class="co">#&gt; 2    3    7       9</span></span>
<span id="cb29-7"><a href="#cb29-7" tabindex="-1"></a><span class="co">#&gt; 3    7    9      10</span></span>
<span id="cb29-8"><a href="#cb29-8" tabindex="-1"></a><span class="co">#&gt; 4    9   10      12</span></span></code></pre></div>
<p>Now, let us see the effect of the additive transformation in the
training examples:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>timeS <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">12</span>))</span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(timeS, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">trend =</span> <span class="st">&quot;additive&quot;</span>, <span class="at">transform_features =</span> <span class="cn">FALSE</span>)</span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a><span class="fu">cbind</span>(m<span class="sc">$</span>features, <span class="at">Targets =</span> m<span class="sc">$</span>targets)</span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a><span class="co">#&gt;   Lag2 Lag1 Targets</span></span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a><span class="co">#&gt; 1    1    3     5.0</span></span>
<span id="cb30-6"><a href="#cb30-6" tabindex="-1"></a><span class="co">#&gt; 2    3    7     4.0</span></span>
<span id="cb30-7"><a href="#cb30-7" tabindex="-1"></a><span class="co">#&gt; 3    7    9     2.0</span></span>
<span id="cb30-8"><a href="#cb30-8" tabindex="-1"></a><span class="co">#&gt; 4    9   10     2.5</span></span></code></pre></div>
<p>Apart from transforming the targets, it is also possible to transform
the features. A vector of features is transformed by substracting the
mean of the vector. Let us see the effects of this transformation:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>timeS <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">12</span>))</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(timeS, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">trend =</span> <span class="st">&quot;additive&quot;</span>, <span class="at">transform_features =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a><span class="fu">cbind</span>(m<span class="sc">$</span>features, <span class="at">Targets =</span> m<span class="sc">$</span>targets)</span>
<span id="cb31-4"><a href="#cb31-4" tabindex="-1"></a><span class="co">#&gt;   Lag2 Lag1 Targets</span></span>
<span id="cb31-5"><a href="#cb31-5" tabindex="-1"></a><span class="co">#&gt; 1 -1.0  1.0     5.0</span></span>
<span id="cb31-6"><a href="#cb31-6" tabindex="-1"></a><span class="co">#&gt; 2 -2.0  2.0     4.0</span></span>
<span id="cb31-7"><a href="#cb31-7" tabindex="-1"></a><span class="co">#&gt; 3 -1.0  1.0     2.0</span></span>
<span id="cb31-8"><a href="#cb31-8" tabindex="-1"></a><span class="co">#&gt; 4 -0.5  0.5     2.5</span></span></code></pre></div>
<p>The point of transforming the features is to remove the effects of
the level of the series in the feature space. Our experience tells us
that transforming the features tends to improve forecast accuracy.</p>
<p>Next, we forecast the airmiles series using the additive
transformation and a random forest model:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(airmiles, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>)</span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb32-3"><a href="#cb32-3" tabindex="-1"></a><span class="fu">autoplot</span>(f)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>By default, the additive transformation is applied to both targets
and features.</p>
</div>
<div id="the-multiplicative-transformation" class="section level2">
<h2>The multiplicative transformation</h2>
<p>The multiplicative transformation is similar to the additive
transformation, but it is intended for series with an exponential trend
(the additive transformation is suited for series with a linear trend).
In the multiplicative transformation a training example is transformed
this way:</p>
<ul>
<li>The target associated with a vector of features is transformed by
dividing it by the mean of its associated vector of features.</li>
<li>To back transform a prediction, the prediction is multiplied by the
mean of the input vector.</li>
<li>Optionally, a vector of features is transformed by dividing it by
its mean.</li>
</ul>
<p>Let us see an example of an artificial time series with a
multiplicative trend and its forecast using the additive and the
multiplicative transformation:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">ts</span>(<span class="dv">10</span> <span class="sc">*</span> <span class="fl">1.05</span><span class="sc">^</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>))</span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a>m_m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(t, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">trend =</span> <span class="st">&quot;multiplicative&quot;</span>)</span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a>f_m <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m_m, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a>m_a <span class="ot">&lt;-</span> <span class="fu">create_model</span>(t, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">trend =</span> <span class="st">&quot;additive&quot;</span>)</span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a>f_a <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m_a, <span class="at">h =</span> <span class="dv">4</span>)</span>
<span id="cb33-6"><a href="#cb33-6" tabindex="-1"></a><span class="fu">library</span>(vctsfr)</span>
<span id="cb33-7"><a href="#cb33-7" tabindex="-1"></a><span class="fu">plot_predictions</span>(t, <span class="at">predictions =</span> <span class="fu">list</span>(<span class="at">Multiplicative =</span> f_m<span class="sc">$</span>pred, <span class="at">Additive =</span> f_a<span class="sc">$</span>pred))</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
<p>In this case, the forecast with the multiplicative transformation
captures perfectly the exponential trend.</p>
<p>As another example, let us compare the additive and multiplicative
transformation applied to the <code>AirPassengers</code> series. This
monthly series has an exponential trend.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a>m_m <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>, <span class="at">trend =</span> <span class="st">&quot;multiplicative&quot;</span>)</span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a>f_m <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m_m, <span class="at">h =</span> <span class="dv">36</span>)</span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a>m_a <span class="ot">&lt;-</span> <span class="fu">create_model</span>(AirPassengers, <span class="at">lags =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>, <span class="at">trend =</span> <span class="st">&quot;additive&quot;</span>)</span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a>f_a <span class="ot">&lt;-</span> <span class="fu">forecast</span>(m_a, <span class="at">h =</span> <span class="dv">36</span>)</span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a><span class="fu">library</span>(vctsfr)</span>
<span id="cb34-6"><a href="#cb34-6" tabindex="-1"></a><span class="fu">plot_predictions</span>(AirPassengers, <span class="at">predictions =</span> <span class="fu">list</span>(<span class="at">Multiplicative =</span> f_m<span class="sc">$</span>pred, <span class="at">Additive =</span> f_a<span class="sc">$</span>pred))</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p>
</div>
</div>
<div id="default-parameters" class="section level1">
<h1>Default parameters</h1>
<p>The <code>create_model()</code> function only has one compulsory
parameter: the time series with which the model is trained. Next, we
discuss the default values for the rest of its parameters:</p>
<ul>
<li><code>lags</code>: The <code>lags</code> parameter is an integer
vector (in increasing order) with the autoregressive lags. If
<code>frequency(ts) == f</code> where <code>ts</code> is the time series
being forecast and <span class="math inline">\(f &gt; 1\)</span> then
the lags used as autoregressive features are 1:<em>f</em>. For example,
the lags for quarterly data are 1:4 and for monthly data 1:12. This is
useful to capture a possible seasonal behavior of the series. If
<code>frequency(ts) == 1</code>, then:
<ul>
<li>The lags with significant autocorrelation in the partial
autocorrelation function (<code>stats::pacf()</code>) are selected.</li>
<li>If no lag has a significant autocorrelation, then lags 1:5 are
chosen.</li>
<li>If only one lag has significant autocorrelation and the additive or
multiplicative transformation is applied to both the targets and the
features, then lags 1:5 are chosen. This is done because it does not
make sense to use these transformations with the features when only one
autoregressive lag is used.</li>
</ul></li>
<li><code>method</code>: By default, the K-nearest neighbors algorithm
is applied.</li>
<li><code>param</code>: By default, the model is trained using some
sensible parameters, normally the default values of the function used to
train the model.</li>
<li><code>trend</code>: The additive transformation is applied. This
transformation have proved its effectiveness to forecast trending
series. In general, its application seems beneficial on any kind of
series.</li>
<li><code>transform_features</code>: Its default value is
<code>TRUE</code>, so that if a series is transformed with the additive
or multiplicative transformation both its features and targets are
transformed.</li>
</ul>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
